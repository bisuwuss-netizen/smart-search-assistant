"""
FastAPI æœåŠ¡å™¨ - æä¾› RESTful API å’Œ SSE æµå¼è¾“å‡º

å¯åŠ¨æ–¹å¼ï¼š
    cd smart-search-assistant
    uvicorn src.api.server:app --reload --port 8000

API ç«¯ç‚¹ï¼š
    POST /ask         - æ™®é€šé—®ç­”ï¼ˆè¿”å›å®Œæ•´ç»“æœï¼‰
    POST /ask/stream  - æµå¼é—®ç­”ï¼ˆSSE å®æ—¶è¾“å‡ºï¼‰
    POST /documents   - ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    GET  /documents   - åˆ—å‡ºå·²ç´¢å¼•æ–‡æ¡£
    DELETE /documents - æ¸…ç©ºçŸ¥è¯†åº“
    GET  /health      - å¥åº·æ£€æŸ¥
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

import asyncio
import json
import uuid
import tempfile
from typing import Optional, List
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from src.graph_advanced import graph_advanced, create_initial_state
from src.rag.rag_manager import RAGManager
from src.config import Config


# ============ Pydantic æ¨¡å‹ ============
class AskRequest(BaseModel):
    """é—®ç­”è¯·æ±‚"""
    query: str
    thread_id: Optional[str] = None
    use_multi_query: bool = True
    max_loops: int = 3


class AskResponse(BaseModel):
    """é—®ç­”å“åº”"""
    answer: str
    sources: List[dict]
    search_type: str
    loop_count: int
    reflection_result: str
    expanded_queries: List[str]
    thread_id: str


class DocumentInfo(BaseModel):
    """æ–‡æ¡£ä¿¡æ¯"""
    filename: str
    chunks: int


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”"""
    status: str
    document_count: int
    version: str


# ============ åº”ç”¨åˆå§‹åŒ– ============
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    print("ğŸš€ Smart Search Assistant API å¯åŠ¨ä¸­...")
    # é¢„çƒ­ RAG ç®¡ç†å™¨
    RAGManager.get_instance()
    print("âœ… æœåŠ¡å°±ç»ª")
    yield
    print("ğŸ‘‹ æœåŠ¡å…³é—­")


app = FastAPI(
    title="Smart Search Assistant API",
    description="åŸºäº LangGraph çš„æ™ºèƒ½æœç´¢åŠ©æ‰‹ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============ API ç«¯ç‚¹ ============

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    rag = RAGManager.get_instance()
    return HealthResponse(
        status="healthy",
        document_count=rag.count(),
        version="1.0.0"
    )


@app.post("/ask", response_model=AskResponse)
async def ask(request: AskRequest):
    """
    æ™®é€šé—®ç­”æ¥å£

    è¿”å›å®Œæ•´çš„å›ç­”ç»“æœï¼Œé€‚åˆå¯¹å»¶è¿Ÿä¸æ•æ„Ÿçš„åœºæ™¯
    """
    thread_id = request.thread_id or str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    state = create_initial_state(
        query=request.query,
        use_multi_query=request.use_multi_query,
        max_loops=request.max_loops
    )

    try:
        result = await asyncio.to_thread(
            graph_advanced.invoke, state, config
        )

        return AskResponse(
            answer=result.get("final_answer", ""),
            sources=result.get("sources", []),
            search_type=result.get("search_type", ""),
            loop_count=result.get("loop_count", 0),
            reflection_result=result.get("reflection_result", ""),
            expanded_queries=result.get("expanded_queries", []),
            thread_id=thread_id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ask/stream")
async def ask_stream(request: AskRequest):
    """
    æµå¼é—®ç­”æ¥å£ï¼ˆSSEï¼‰

    å®æ—¶è¿”å›å¤„ç†çŠ¶æ€å’Œæœ€ç»ˆç­”æ¡ˆï¼Œé€‚åˆéœ€è¦å±•ç¤ºè¿›åº¦çš„åœºæ™¯

    SSE äº‹ä»¶æ ¼å¼ï¼š
        event: step
        data: {"step": "ğŸ”„ æ­£åœ¨æ‰©å±•æŸ¥è¯¢...", "progress": 20}

        event: answer
        data: {"answer": "...", "sources": [...]}

        event: done
        data: {"status": "completed"}
    """
    thread_id = request.thread_id or str(uuid.uuid4())

    async def event_generator():
        config = {"configurable": {"thread_id": thread_id}}
        state = create_initial_state(
            query=request.query,
            use_multi_query=request.use_multi_query,
            max_loops=request.max_loops
        )

        steps = [
            ("decide", "ğŸ¤” åˆ¤æ–­æœç´¢ç±»å‹...", 10),
            ("expand", "ğŸ”„ æ‰©å±•æŸ¥è¯¢...", 20),
            ("search", "ğŸ” æ‰§è¡Œæœç´¢...", 40),
            ("reflect", "ğŸ§ è¯„ä¼°ç»“æœ...", 60),
            ("answer", "âœï¸ ç”Ÿæˆç­”æ¡ˆ...", 80),
        ]

        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"event: start\ndata: {json.dumps({'thread_id': thread_id, 'query': request.query})}\n\n"

            # æ¨¡æ‹Ÿæ­¥éª¤è¿›åº¦ï¼ˆå®é™…å¯ä»¥é€šè¿‡å›è°ƒè·å–ï¼‰
            for step_name, step_desc, progress in steps:
                yield f"event: step\ndata: {json.dumps({'step': step_desc, 'progress': progress})}\n\n"
                await asyncio.sleep(0.1)

            # æ‰§è¡Œå®é™…æŸ¥è¯¢
            result = await asyncio.to_thread(
                graph_advanced.invoke, state, config
            )

            # å‘é€ç­”æ¡ˆ
            answer_data = {
                "answer": result.get("final_answer", ""),
                "sources": result.get("sources", []),
                "search_type": result.get("search_type", ""),
                "loop_count": result.get("loop_count", 0),
                "reflection_result": result.get("reflection_result", ""),
                "expanded_queries": result.get("expanded_queries", [])
            }
            yield f"event: answer\ndata: {json.dumps(answer_data, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæˆäº‹ä»¶
            yield f"event: done\ndata: {json.dumps({'status': 'completed', 'thread_id': thread_id})}\n\n"

        except Exception as e:
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


@app.post("/documents", response_model=DocumentInfo)
async def upload_document(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = None
):
    """
    ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“

    æ”¯æŒæ ¼å¼ï¼š.pdf, .txt, .md
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = ('.pdf', '.txt', '.md')
    if not file.filename.lower().endswith(allowed_extensions):
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒ: {', '.join(allowed_extensions)}"
        )

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = tmp.name

    try:
        rag = RAGManager.get_instance()
        chunks = rag.add_document(tmp_path)

        return DocumentInfo(
            filename=file.filename,
            chunks=chunks
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_path)


@app.get("/documents")
async def list_documents():
    """åˆ—å‡ºå·²ç´¢å¼•çš„æ–‡æ¡£"""
    rag = RAGManager.get_instance()
    documents = rag.list_documents()
    return {
        "count": len(documents),
        "documents": documents
    }


@app.delete("/documents")
async def clear_documents():
    """æ¸…ç©ºçŸ¥è¯†åº“"""
    rag = RAGManager.get_instance()
    rag.clear()
    return {"message": "çŸ¥è¯†åº“å·²æ¸…ç©º"}


# ============ ä¸»å…¥å£ ============
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "src.api.server:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
