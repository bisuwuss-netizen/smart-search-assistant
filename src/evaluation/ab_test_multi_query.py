"""
Multi-Query A/B å¯¹ç…§å®éªŒ (ä¼˜åŒ–ç‰ˆ)

é€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯æŸ¥è¯¢æ‰©å±•ï¼ˆMulti-Queryï¼‰å¯¹æ£€ç´¢è´¨é‡å’Œæ‰§è¡Œæ•ˆç‡çš„å½±å“ã€‚
"""
import asyncio
from src.graph import graph
from src.evaluation.rag_evaluator import RAGEvaluator

# ğŸ§ª å¤æ‚çš„æµ‹è¯•ç”¨ä¾‹ï¼ˆéœ€è¦å¤šç»´åº¦å¬å›ï¼‰
TEST_CASES = [
    {
        "question": "LangGraph çš„çŠ¶æ€ç®¡ç†æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿè¯·è¯¦ç»†è¯´æ˜ checkpoint, thread_id å’Œ State çš„å…³ç³»ã€‚",
        "expected_answer": "LangGraph é€šè¿‡ StateGraph å®šä¹‰çŠ¶æ€ç»“æ„(State)ï¼Œä½¿ç”¨æ£€æŸ¥ç‚¹(checkpoint)æŒä¹…åŒ–çŠ¶æ€. thread_id ç”¨äºæ ‡è¯†ä¸åŒçš„ä¼šè¯ï¼Œä½¿å¾—ç³»ç»Ÿå¯ä»¥æ¢å¤å’Œç»§ç»­ç‰¹å®š thread çš„æ‰§è¡Œè¿‡ç¨‹ã€‚"
    },
    {
        "question": "åˆ†ææ™ºèƒ½æœç´¢åŠ©æ‰‹ï¼ˆSmart Search Assistantï¼‰ä¸­åæ€æœºåˆ¶ï¼ˆReflectorï¼‰çš„ä½œç”¨åŠå…¶æµç¨‹ã€‚",
        "expected_answer": "åæ€æœºåˆ¶é€šè¿‡ LLM è¯„ä¼°æ£€ç´¢ç»“æœçš„å……åˆ†æ€§ã€‚æµç¨‹åŒ…æ‹¬ï¼šè¯„ä¼°ä¿¡æ¯ã€åˆ¤æ–­æ˜¯å¦è¶³å¤Ÿï¼ˆSUFFICIENT/INSUFFICIENTï¼‰ã€è‹¥ä¸è¶³åˆ™ç”Ÿæˆæ”¹è¿›æŸ¥è¯¢å¹¶é‡è¯•æœç´¢ï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°æˆ–ä¿¡æ¯æ»¡è¶³è¦æ±‚ã€‚"
    },
    {
        "question": "å°åº¦ä¸ä¸œç›Ÿåœ¨æ•°å­—ç»æµåˆä½œä¸­é¢ä¸´å“ªäº›æŒ‘æˆ˜ï¼Ÿåˆ†åˆ«ä»æ”¿ç­–å’ŒåŸºç¡€è®¾æ–½ä¸¤ä¸ªè§’åº¦è¯´æ˜ã€‚",
        "expected_answer": "é¢ä¸´æŒ‘æˆ˜åŒ…æ‹¬æ”¿ç­–å±‚é¢çš„ç›‘ç®¡å·®å¼‚ã€æ•°æ®éšç§æ ‡å‡†ä¸ä¸€ï¼›ä»¥åŠåŸºç¡€è®¾æ–½å±‚é¢çš„æ•°å­—é¸¿æ²Ÿã€ç½‘ç»œè¿æ¥ä¸å‡è¡¡å’Œè·¨å¢ƒæ”¯ä»˜ç³»ç»Ÿçš„å…¼å®¹æ€§é—®é¢˜ã€‚"
    }
]

async def run_experimental_run(use_multi_query: bool):
    """
    è¿è¡Œä¸€ç»„å®éªŒ
    """
    print(f"\nğŸš€ å¼€å§‹å®éªŒ: {'Multi-Query (å¼€å¯)' if use_multi_query else 'Baseline (å…³é—­)'}")
    print("=" * 60)
    
    samples = []
    loop_counts = []
    evaluator = RAGEvaluator()
    
    for i, case in enumerate(TEST_CASES, 1):
        q = case["question"]
        print(f"[{i}/{len(TEST_CASES)}] å¤„ç†é—®é¢˜: {q[:40]}...")
        
        # æ„é€ åˆå§‹çŠ¶æ€
        state = {
            "messages": [],
            "current_query": q,
            "use_multi_query": use_multi_query,
            "max_loops": 3,
            "loop_count": 0
        }
        
        # è¿è¡Œå›¾
        config = {"configurable": {"thread_id": f"ab-test-{'mq' if use_multi_query else 'base'}-{i}"}}
        result = graph.invoke(state, config)
        
        # è®°å½•å¾ªç¯æ¬¡æ•°
        final_loops = result.get("loop_count", 0)
        loop_counts.append(final_loops)
        
        # æ”¶é›†ä¸Šä¸‹æ–‡
        contexts = []
        if result.get("local_contexts"):
            contexts.append(result["local_contexts"])
        if result.get("search_results"):
            contexts.append(result["search_results"])
            
        samples.append({
            "question": q,
            "answer": result["final_answer"],
            "contexts": contexts,
            "expected_answer": case["expected_answer"]
        })
        
    print("\nğŸ” æ­£åœ¨è¯„ä¼°è´¨é‡æŒ‡æ ‡...")
    report = evaluator.evaluate_batch(samples)
    avg_loops = sum(loop_counts) / len(loop_counts)
    return report, avg_loops

async def main():
    # 1. è¿è¡Œ Baseline
    baseline_report, base_avg_loops = await run_experimental_run(use_multi_query=False)
    
    # 2. è¿è¡Œ Multi-Query ç‰ˆ
    mq_report, mq_avg_loops = await run_experimental_run(use_multi_query=True)
    
    # 3. è¾“å‡ºå¯¹æ¯”è¡¨æ ¼
    print("\n" + "ğŸ†" * 10 + " A/B å®éªŒæœ€ç»ˆç»“æœå¯¹æ¯” " + "ğŸ†" * 10)
    print("-" * 85)
    print(f"{'æŒ‡æ ‡ (Metric)':<30} | {'Baseline':<15} | {'Multi-Query':<15} | {'æå‡ (Lift)':<10}")
    print("-" * 85)
    
    metrics = [
        ("å¿ å®åº¦ (Faithfulness)", baseline_report.avg_faithfulness, mq_report.avg_faithfulness),
        ("ç­”æ¡ˆç›¸å…³æ€§ (Relevancy)", baseline_report.avg_answer_relevancy, mq_report.avg_answer_relevancy),
        ("æ£€ç´¢ç²¾ç¡®åº¦ (Precision)", baseline_report.avg_context_precision, mq_report.avg_context_precision),
        ("æ£€ç´¢å¬å›ç‡ (Recall)", baseline_report.avg_context_recall, mq_report.avg_context_recall),
    ]
    
    for name, base, mq in metrics:
        lift = (mq - base) / base if base > 0 else 0
        print(f"{name:<24} | {base:>14.2%} | {mq:>14.2%} | {lift:>+10.1%}")
    
    # æ•ˆç‡æŒ‡æ ‡
    loop_reduction = (base_avg_loops - mq_avg_loops) / base_avg_loops if base_avg_loops > 0 else 0
    print("-" * 85)
    print(f"{'å¹³å‡æ£€ç´¢å¾ªç¯æ•° (Avg Loops)':<24} | {base_avg_loops:>14.2f} | {mq_avg_loops:>14.2f} | {loop_reduction:>+10.1%}")
    print("-" * 85)

if __name__ == "__main__":
    asyncio.run(main())
