{
  "total_samples": 2,
  "avg_faithfulness": 0.975,
  "avg_answer_relevancy": 1.0,
  "avg_context_precision": 0.975,
  "avg_context_recall": 0.835,
  "results": [
    {
      "question": "什么是 LangGraph？",
      "expected_answer": "LangGraph 是一个用于构建有状态、多角色的 LLM 应用的框架。",
      "generated_answer": "LangGraph 是一个开源的框架，由 LangChain 开发，用于构建和管理基于大型语言模型（LLM）的复杂、有状态的 AI 代理（Agent）工作流 [来源1]。它采用图结构（graph-based architecture）来建模 AI 工作流程，使开发者能够精确控制多步骤、多角色的 AI 应用程序中的任务执行顺序、状态流转与决策逻辑 [来源3]。\n\n在 LangGraph 中，工作流被定义为一个**状态图（StateGraph）**，其中节点（nodes）代表具体的处理步骤（如调用 LLM、执行工具、条件判断等），边（edges）表示控制流的转移路径。整个流程维护一个中央状态对象（state），该状态在节点间传递并持续更新，支持跨步骤的数据共享与持久化 [来源3]。这种设计使得 LangGraph 特别适合需要循环、条件分支或人工干预的动态流程，例如 RAG（检索增强生成）、自动化代理协作系统等。\n\nLangGraph 并非独立于 LangChain 的全新框架，而是 LangChain 生态系统的一部分，可以与 LangChain 的链（Chains）、LangChain Expression Language（LCEL）、工具（Tools）和记忆机制（Memory）无缝集成 [来源3]。它提供低级别的编排能力，适用于需要精细控制代理行为的场景，同时也支持高级接口以简化常见代理类型的开发 [来源3]。\n\n此外，LangGraph 支持异步执行、检查点持久化（checkpointing）和可视化调试，增强了应用的可观测性与容错能力，已被 Klarna、Replit、Elastic 等公司用于构建生产级的智能代理系统 [来源2][来源3]。\n\n总之，LangGraph 是一个强大的代理编排框架，通过图结构实现对 LLM 驱动应用的灵活、可控和可扩展的管理 [来源1]。\n\n---\n[来源1] https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/  \n[来源2] https://docs.langchain.com/oss/python/langgraph/overview  \n[来源3] https://blog.csdn.net/musicml/article/details/136441895",
      "contexts": [
        "{'query': '什么是 LangGraph？', 'follow_up_questions': None, 'answer': 'LangGraph is an open-source framework that uses graph structures to manage complex workflows and agents based on large language models. It allows developers to define and orchestrate multi-step AI processes. It is part of the LangChain ecosystem.', 'images': [], 'results': [{'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/', 'title': 'What is LangGraph? - GeeksforGeeks', 'content': '# What is LangGraph?\\n\\nLast Updated : \\n12 Dec, 2025\\n\\nSuggest changes\\n\\n1 Likes\\n\\nLangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. At its core, LangGraph combines large language models (LLMs) with graph-based architectures allowing developers to map, organize and optimize how AI agents interact and make decisions.', 'score': 0.94339466, 'raw_content': None}, {'url': 'https://docs.langchain.com/oss/python/langgraph/overview', 'title': 'LangGraph overview - Docs by LangChain', 'content': 'Trusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents.LangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools.We will commonly use LangChain components throughout the', 'score': 0.942385, 'raw_content': None}, {'url': 'https://blog.csdn.net/musicml/article/details/136441895', 'title': '一文搞懂LangChain 新利器：LangGraph 原创 - CSDN博客', 'content': 'LangGraph 是一个有用于构建有状态和多角色的 Agents 应用，它并不是一个独立于 Langchain 的新框架，而是基于 Langchain 之上构建的一个扩展库，可以与 Langchain 现有的链（Chains）、LangChain Expression Language（LCEL）等无缝协作。LangGraph 能够协调多个 Chain、Agent、Tool 等共同协作来完成输入任务，支持 LLM 调用“循环”和 Agent 过程的更精细化控制。\\n\\nLangGraph 的实现方式是把之前基于 AgentExecutor 的黑盒调用过程，用一种新的形式来构建：状态图（StateGraph）。把基于 LLM 的任务（比如：RAG、代码生成等）细节用 Graph 进行精确的定义（定义图的节点与边），最后基于这个图来编译生成应用。在任务运行过程中，维持一个中央状态对象(state)，会根据节点的跳转不断更新，状态包含的属性可自行定义。\\n\\n我们一起剖析下官方 RAG 应用的 Graph 案例，如下图所示，从而更好理解 LangGraph。 [...] LangGraph 是 LangChain 生态系统的一部分，专门用于构建基于 LLM（大型语言模型）的复杂工作流和 Agent 系统。它采用有向图结构来定义工作流程，使开发者能够创建动态、可控且可扩展的 AI 应用程序。简单来说，LangGraph 是一个框架，允许你使用图结构来定义 LLM 应用程序的不同组件如何交互，从而实现复杂的、多步骤的 AI 工作流程。LangGraph 是构建复杂 AI 工作流的强大工具，它提供了灵活的流程控制、强大的状态管理和良好的集成能力。\\n\\nLangGraph简介\\n\\n大多\\\\_C的博客\\n\\n06-01  2577\\n\\nLangGraph是 LangChain 的一个扩展，旨在通过将步骤建模为图中的边缘和节点，构建具有大型语言模型（LLMs）的强大和有状态的多角色应用程序。LangGraph 提供了用于创建常见类型代理的高级接口，以及用于组合自定义流程的低级 API。\\n\\n【LLM大模型】LangChain框架：Agent之LangGraph的使用\\n\\nDEVELOPERAA的博客\\n\\n07-30  3292 [...] 摘要： LangGraph是针对LLM/Agent体系中复杂任务（如状态管理、多agent协作、动态控制流）设计的底层框架，强调图化结构、状态维护和可控流程。其核心包括节点（任务单元）、边（控制流）、状态管理（共享/局部数据）和执行引擎（调度、容错、人工干预）。支持与LLM、工具、Memory集成，并提供可视化调试工具。开源实现包括Python版（LangChain官方）和Java版（LangGraph4j），均具备异步执行、检查点持久化和生态集成能力，旨在为开发者提供灵活、可观测的Agent编排方案。\\n\\n彻底搞懂LangGraph【1】：构建复杂智能体应用的LangChain新利器\\n\\n热门推荐\\n\\njuan9872的博客\\n\\n04-12  1万+\\n\\n图是计算机科学中的一种数据结构。大部分人可能都接触过一些基本的数据结构，比如队列（Queue）、堆栈（Stack）、链表（List）或者树（Tree）等，图（Graph）也是其中的一种相对复杂的数据结构。\\n\\n01｜Langgraph | 从入门到实战 | 基础篇\\n\\n稳稳C9的博客\\n\\n10-21  2588', 'score': 0.9304142, 'raw_content': None}], 'response_time': 0.0, 'request_id': '5bda6790-ca60-4953-8262-5a53594ad40a'}"
      ],
      "faithfulness": 1.0,
      "answer_relevancy": 1.0,
      "context_precision": 1.0,
      "context_recall": 1.0
    },
    {
      "question": "RAG 的核心步骤是什么？",
      "expected_answer": "RAG 的核心步骤包括：检索（Retrieval）、增强（Augmentation）、生成（Generation）。",
      "generated_answer": "RAG（Retrieval-Augmented Generation，检索增强生成）的核心步骤主要包括以下几个阶段：\n\n1. **数据准备与加载**：首先需要收集外部知识源的数据，如文档、数据库、网页等，并将其导入系统。这一步通常包括对原始数据进行清洗、分割成文本块（chunks）等预处理操作 [来源2]。\n\n2. **嵌入与索引（Embedding and Indexing）**：使用嵌入模型（embedding model）将文本块转换为向量表示，并存储到向量数据库中，以便后续进行语义相似度检索。该过程构建了可用于高效检索的索引结构 [来源1]。\n\n3. **检索（Retrieval）**：当用户提出查询时，系统将查询也转化为向量，并在向量数据库中搜索与其最相关的文档或文本片段。这一阶段可结合稀疏检索（如BM25）和密集检索（如DPR）方法以提高准确性 [来源3]。\n\n4. **后处理（Node Post-processing）**：对检索到的结果进行重排序、过滤或补充元信息等操作，以优化输入生成模型的内容质量 [来源2]。\n\n5. **生成响应（Response Synthesis）**：将检索出的相关信息与原始查询组合成一个增强的提示（prompt），输入给大型语言模型（LLM），由其生成最终的自然语言回答。此过程利用了上下文学习（In-Context Learning）机制来提升输出的准确性和相关性 [来源1][来源3]。\n\n此外，一些高级RAG系统还包括评估环节，用于衡量生成结果的准确性、忠实度和响应速度 [来源2]。\n\n综上所述，RAG的核心步骤可以概括为：**数据加载 → 嵌入与索引 → 检索 → 后处理 → 生成回答** [来源1][来源2][来源3]。",
      "contexts": [
        "{'query': 'RAG 的核心步骤是什么？', 'follow_up_questions': None, 'answer': 'RAG combines retrieval and generation, using external knowledge to enhance model outputs. Core steps include retrieval of relevant documents, embedding, and generation of responses. The process leverages large language models for final text generation.', 'images': [], 'results': [{'url': 'https://blog.csdn.net/2401_82452722/article/details/135934144', 'title': '读懂RAG这一篇就够了，万字详述RAG的5步流程和12个优化策略原创', 'content': 'ChatGPT、GLM等一众生成式人工智能在文本创作及文本至图像转换等领域，展现出了令人瞩目的能力。然而，这些尖端技术亦非尽善尽美，其固有的局限性如同暗礁，潜藏着诸如生成内容的虚幻性、解释性的缺失、专业知识的浅薄，以及对时代新知把握的不足等问题。为了跨越这些障碍，提升模型的效能，研究者们探索出两条主要路径：一是通过微调（Fine Tune）技术，让模型在既有基础上进一步精进；二是赋予模型与外界交互的能力，使其能够以多元的方式汲取新知。 微调技术，无疑如同一把锐利的手术刀，能够精准地雕琢模型，使其深谙私域知\\n\\nRAG的核心流程详解：从信息检索到生成\\n\\nchenwr\\\\_727的博客\\n\\n09-09\\n\\n1179\\n\\nRAG（Retrieval-Augmented Generation）技术将信息检索和文本生成结合起来，通过检索相关信息来提升生成模型的性能。下面是RAG的核心流程的详细解析，从输入处理到生成阶段，再到最终的输出处理。\\n\\nRAG 的完整流程是怎么样的？\\n\\nRookie\\n\\n09-02\\n\\n491\\n\\n也可以从。\\n\\nRAG 基本流程及处理技巧 with LangChain [...] RAG(检索增强生成 )\\\\_rag csdn-CSDN博客\\n\\n12-15\\n\\n☁️博客首页:CSDN主页听风与他 🌄每日一句:狠狠沉淀,顶峰相见 目录 📑前言 RAG 1.RAG定义 2.RAG技术演化 3.RAG优势 LangChain实现RAG 1.基础环境准备 2.在项目根目录创建.env文件,用来存放相关配置(configuration.env) 3.准备一个矢量数据库来保存所有附加信息的外部知识源。\\n\\n一文读懂AI大模型时代的RAG技术\\n\\nawei0916的专栏\\n\\n04-17\\n\\n1847\\n\\nRAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合检索技术与生成模型的技术架构，旨在通过动态引入外部知识库增强大语言模型（LLM）的生成能力。其核心思想是通过检索系统从外部数据源（如企业知识库、实时文档等）获取相关信息，并将检索结果作为上下文输入生成模型，以提高生成答案的准确性、时效性和专业性\\n\\n24-大模型（LLMs）RAG 优化策略 —— RAG-Fusion篇.pdf\\n\\n12-31 [...] 另一种解决方案，RAG（Retrieval Augmented Generation）为生成式模型提供了与外部世界互动提供了一个很有前景的解决方案。RAG的主要作用类似搜索引擎，找到用户提问最相关的知识或者是相关的对话历史，并结合原始提问（查询），创造信息丰富的prompt，指导模型生成准确输出。其本质上应用了情境学习（In-Context Learning）的原理。\\n\\n在大型语言模型（LLM）领域，创建一个最小可行产品相对简单，但实现生产级性能和可用性是一个艰巨的任务，特别是构建高性能的RAG系统。RAG已在企业私域知识问答等领域广泛应用，例如，现在主流的各类chat to PDF，chat to doc等应用都是基于RAG来搭建的。\\n\\n如下图所示RAG可分为5个基本流程：知识文档的准备；嵌入模型嵌入模型（embedding model）；向量数据库；查询检索和生产回答。下面会对每个环节进行详细描述：\\n\\n NO.1  知识文档的准备\\n\\n NO.2   嵌入模型', 'score': 0.8173562, 'raw_content': None}, {'url': 'https://www.aneasystone.com/archives/2024/06/advanced-rag-notes.html', 'title': '高级RAG 技术学习笔记', 'content': '通过上面的学习，我们对 LlamaIndex 中的各个组件的概念已经有了一个大致的了解，可以结合官网的 Learn、Use Cases 和 Component Guides 等文档学习 LlamaIndex 的更多功能。\\n\\n## 高级 RAG 技巧\\n\\n基于 LlamaIndex，我们只用了 5 行代码就实现了一个简单的 RAG 系统，可以看出，这是朴素 RAG 的基本思路。这一节我们将继续学习高级 RAG 技巧，争取对每一种技巧都进行实战验证，带大家一窥 RAG 的技术全貌。\\n\\n下图展示了高级 RAG 涉及的核心步骤和算法：\\n\\nLangChain 的 这篇博客 对这些步骤进行详细的讨论。\\n\\n### 查询转换（Query Transformations）\\n\\nRAG 系统面临的第一个问题就是如何处理用户输入，我们知道，RAG 的基本思路是根据用户输入检索出最相关的内容，但是用户输入是不可控的，可能存在冗余、模糊或歧义等情况，如果直接拿着用户输入去检索，效果可能不理想。 [...] + 加载完文档，构造完索引，我们就来到 RAG 中最重要的一环：Querying；根据用户的问题，或者是一个总结请求，或者一个更复杂的指令，检索出相关文档从而实现对数据的问答和聊天；\\n  + 查询引擎（Query Engines） 是最基础也是最常见的检索方式，通过 Index 的 `as_query_engine()` 方法可以构建查询引擎，查询引擎是无状态的，不能跟踪历史对话，如果要实现类似 ChatGPT 的对话场景，可以通过 `as_chat_engine()` 方法构建 聊天引擎（Chat Engines）；\\n  + LlamaIndex 将查询分为三个步骤：第一步 Retrieval 是指从 Index 中找到并返回与用户查询最相关的文档；第二步 Node Postprocessing 表示后处理，这是在检索到结果后对其进行重排序、转换或过滤的过程；第三步 Response Synthesis 是指将用户查询、最相关的文档片段以及提示组合在一起发送到大模型以生成响应；查询的每个步骤 LlamaIndex 都内置了多种不同的策略，也可以完全由用户定制； [...] 正如 LlamaIndex 的名字所暗示的，索引（Index） 是 RAG 系统中的核心概念，它是大模型和用户数据之间的桥梁，无论是数据库类的结构化数据，还是文档类的非结构化数据，抑或是程序类的 API 数据，都是通过索引来查询的，查询出来的内容作为上下文和用户的问题一起发送给大模型，得到响应：\\n\\nLlamaIndex 将 RAG 分为五个关键阶段：\\n\\n 加载（Loading）：用于导入各种用户数据，无论是文本文件、PDF、另一个网站、数据库还是 API；LlamaHub 提供了数百个的加载器；\\n 索引（Indexing）：可以是 Embedding 向量，也可以是其他元数据策略，方便我们准确地找到上下文相关的数据；\\n 存储（Storing）：对索引持久化存储，以免重复索引；\\n 查询（Querying）：对给定的索引策略进行查询，包括子查询、多步查询和混合策略；\\n 评估（Evaluation）：提供客观的度量标准，用于衡量查询响应的准确性、忠实度和速度；', 'score': 0.8145405, 'raw_content': None}, {'url': 'https://finance.sina.com.cn/roll/2025-06-05/doc-ineyyzvh1666513.shtml', 'title': '一文看懂RAG：核心技术与实践应用 - 新浪财经', 'content': '模块化RAG将检索和生成管道细分为多个独立的模块，这种模块化设计允许根据不同需求进行灵活配置和优化。它结合了稀疏检索（如传统的关键词匹配）和密集检索（如基于向量的语义检索）方法，根据查询类型的不同，灵活选择最合适的检索方式，以提高检索效率和准确性。同时，它支持与外部API、数据库等多种工具进行集成，拓展了数据来源和处理能力，适用于复杂多领域的任务，如金融分析、法律研究等。\\n\\n三、原理与架构\\n\\n3.1 核心原理\\n\\n\\u3000\\u3000RAG技术的核心思想是将生成模型与检索机制相结合，利用外部知识增强模型的生成能力。具体步骤如下：\\n\\n\\u3000\\u3000检索：根据输入查询，从外部知识源中检索相关文档或信息片段。这通常涉及将用户查询和知识库中的内容转换为向量，然后计算它们之间的相似度，最终返回与查询最相关的知识片段。\\n\\n\\u3000\\u3000生成：将检索到的信息与输入查询结合，输入生成模型，生成最终输出。生成模型通常使用大语言模型，会根据检索到的信息和输入查询，生成连贯且相关的文本。\\n\\n3.2 系统架构\\n\\n一个典型的RAG系统架构包括以下几个关键组件： [...] 文档存储和索引：用于存储和索引外部知识库的内容，通常使用向量数据库实现。向量数据库能够高效地存储和检索高维向量数据，为快速检索提供支持。\\n\\n\\u3000\\u3000嵌入模型：将文本内容转换为向量表示，以便进行相似度搜索。其目标是使得具有相似语义的文字序列对应的向量尽可能接近，而语义不同的文字序列对应的向量尽可能远离。\\n\\n\\u3000\\u3000检索引擎：根据用户查询从知识库中检索相关文档或片段。常用的检索方法包括基于关键词匹配的稀疏检索（如BM25）和基于深度学习的密集检索（如DPR、ANCE）。\\n\\n\\u3000\\u3000提示生成器：将检索结果和用户查询组合成适合LLM处理的提示。一个好的提示模板应该清晰地定义问题的上下文，适当地组织检索到的相关信息，明确地指导LLM的生成方向，并保持合理的长度和复杂度。\\n\\n\\u3000\\u3000大型语言模型：根据提示生成最终响应。大型语言模型接收经过检索增强的提示，并基于这些上下文生成最终的回答。\\n\\n四、工作流程\\n\\nRAG技术的工作流程主要包括以下几个步骤：\\n\\n4.1 数据处理阶段\\n\\n\\u3000\\u3000数据收集：收集各种类型的数据源，如文档、数据库、网页等，构建外部知识库。', 'score': 0.79542017, 'raw_content': None}], 'response_time': 1.58, 'request_id': '7a8b36d5-58c7-4380-abef-b10e46b3089d'}"
      ],
      "faithfulness": 0.95,
      "answer_relevancy": 1.0,
      "context_precision": 0.95,
      "context_recall": 0.67
    }
  ]
}