"""
Human-in-the-loop æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº† LangGraph çš„ interrupt åŠŸèƒ½ï¼š
1. ç”¨æˆ·æé—®åï¼ŒAgent åˆ¤æ–­éœ€è¦ä»€ä¹ˆç±»å‹çš„æœç´¢
2. åœ¨æ‰§è¡Œæœç´¢å‰æš‚åœï¼Œå±•ç¤ºå³å°†æ‰§è¡Œçš„æ“ä½œ
3. ç”¨æˆ·ç¡®è®¤åæ‰çœŸæ­£æ‰§è¡Œæœç´¢
4. è¿™ç§æ¨¡å¼é€‚åˆéœ€è¦äººå·¥å®¡æ‰¹çš„æ•æ„Ÿæ“ä½œ

è¿è¡Œæ–¹å¼ï¼š
    python -m src.examples.interrupt_demo
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.graph_with_interrupt import graph_with_interrupt


def demo_interrupt():
    """æ¼”ç¤º interrupt åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ”§ Human-in-the-loop (Interrupt) æ¼”ç¤º")
    print("=" * 60)
    print("""
è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº† LangGraph çš„ interrupt åŠŸèƒ½ï¼š
- Agent åœ¨æ‰§è¡Œæœç´¢å‰ä¼šæš‚åœ
- ç”¨æˆ·å¯ä»¥æŸ¥çœ‹å³å°†æ‰§è¡Œçš„æ“ä½œ
- ç¡®è®¤åæ‰ä¼šçœŸæ­£æ‰§è¡Œ

è¿™ç§æ¨¡å¼çš„åº”ç”¨åœºæ™¯ï¼š
- æ•æ„Ÿæ“ä½œå‰çš„äººå·¥å®¡æ‰¹
- å¤–éƒ¨ API è°ƒç”¨å‰çš„ç¡®è®¤
- æˆæœ¬æ§åˆ¶ï¼ˆé¿å…ä¸å¿…è¦çš„ API è°ƒç”¨ï¼‰
""")

    config = {"configurable": {"thread_id": "interrupt-demo-1"}}

    questions = [
        "2024å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»æ˜¯è°ï¼Ÿ",  # éœ€è¦ç½‘ç»œæœç´¢
        "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ",  # å¯èƒ½ç”¨æœ¬åœ°çŸ¥è¯†åº“
    ]

    for question in questions:
        print("\n" + "=" * 60)
        print(f"â“ ç”¨æˆ·é—®é¢˜: {question}")
        print("=" * 60)

        # æ„é€ åˆå§‹çŠ¶æ€
        state = {
            "current_query": question,
            "messages": [],
                "search_results": "",
            "final_answer": "",
            "current_step": "",
            "search_type": "",
            "local_contexts": "",
            "sources": [],
            "human_approved": False,
            "pending_action": ""
        }

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šåˆ¤æ–­æœç´¢ç±»å‹ï¼Œç„¶åæš‚åœ
        print("\nğŸ”„ æ­£åœ¨åˆ†æé—®é¢˜...")
        result = graph_with_interrupt.invoke(state, config)

        # æ£€æŸ¥æ˜¯å¦æš‚åœ
        print(f"\nâ¸ï¸  Agent æš‚åœï¼Œç­‰å¾…ç¡®è®¤")
        print(f"   ğŸ“‹ æœç´¢ç±»å‹: {result.get('search_type', 'unknown')}")
        print(f"   ğŸ“ å¾…æ‰§è¡Œæ“ä½œ: {result.get('pending_action', 'N/A')}")

        # ç­‰å¾…ç”¨æˆ·è¾“å…¥
        user_input = input("\nğŸ‘‰ æ˜¯å¦æ‰§è¡Œæ­¤æ“ä½œ? (y=ç¡®è®¤ / n=å–æ¶ˆ / m=ä¿®æ”¹): ").strip().lower()

        if user_input == 'y':
            print("\nâœ… ç”¨æˆ·ç¡®è®¤ï¼Œç»§ç»­æ‰§è¡Œ...")
            # ä¼  None è¡¨ç¤ºç»§ç»­å½“å‰çŠ¶æ€
            final_result = graph_with_interrupt.invoke(None, config)

            print(f"\nğŸ‰ æ‰§è¡Œå®Œæˆ!")
            print(f"   ç­”æ¡ˆé¢„è§ˆ: {final_result.get('final_answer', 'N/A')[:300]}...")

            # æ˜¾ç¤ºæ¥æº
            sources = final_result.get('sources', [])
            if sources:
                print(f"\n   ğŸ“š ä¿¡æ¯æ¥æº:")
                for i, src in enumerate(sources[:3], 1):
                    print(f"      [{i}] {src.get('type', '?')}: {src.get('source', 'N/A')[:50]}")

        elif user_input == 'm':
            # ä¿®æ”¹æœç´¢ç±»å‹
            print("\nå¯é€‰çš„æœç´¢ç±»å‹: local / web / hybrid / none")
            new_type = input("è¯·è¾“å…¥æ–°çš„æœç´¢ç±»å‹: ").strip().lower()
            if new_type in ['local', 'web', 'hybrid', 'none']:
                # æ›´æ–°çŠ¶æ€å¹¶ç»§ç»­
                result['search_type'] = new_type
                print(f"\nå·²ä¿®æ”¹ä¸º: {new_type}ï¼Œç»§ç»­æ‰§è¡Œ...")
                final_result = graph_with_interrupt.invoke(None, config)
                print(f"\nğŸ‰ æ‰§è¡Œå®Œæˆ!")
                print(f"   ç­”æ¡ˆ: {final_result.get('final_answer', 'N/A')[:300]}...")
            else:
                print("âŒ æ— æ•ˆçš„ç±»å‹ï¼Œæ“ä½œå–æ¶ˆ")

        else:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")

        # æ›´æ¢ thread_idï¼Œå¼€å§‹æ–°å¯¹è¯
        config = {"configurable": {"thread_id": f"interrupt-demo-{hash(question)}"}}

    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºç»“æŸ")
    print("=" * 60)


if __name__ == "__main__":
    demo_interrupt()
