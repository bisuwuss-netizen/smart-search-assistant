"""
å¸¦ Human-in-the-loop çš„ Graph

æ ¸å¿ƒæ¦‚å¿µï¼š
- interrupt_before: åœ¨æŒ‡å®šèŠ‚ç‚¹æ‰§è¡Œå‰æš‚åœ
- ç”¨æˆ·å¯ä»¥æŸ¥çœ‹å³å°†æ‰§è¡Œçš„æ“ä½œï¼Œé€‰æ‹©ç¡®è®¤æˆ–ä¿®æ”¹
- è°ƒç”¨ graph.invoke() ä¼šåœ¨ interrupt ç‚¹è¿”å›ï¼Œéœ€è¦å†æ¬¡è°ƒç”¨æ‰èƒ½ç»§ç»­

æµç¨‹ï¼š
    ç”¨æˆ·è¾“å…¥ â†’ decide â†’ [INTERRUPT] â†’ æœç´¢èŠ‚ç‚¹ â†’ answer â†’ è¾“å‡º

ä½¿ç”¨æ–¹å¼ï¼š
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œä¼šåœ¨æœç´¢å‰æš‚åœ
    result = graph.invoke(state, config)
    print(f"å³å°†æ‰§è¡Œ: {result['pending_action']}")

    # ç”¨æˆ·ç¡®è®¤åï¼Œç»§ç»­æ‰§è¡Œ
    result = graph.invoke(None, config)  # ä¼  None è¡¨ç¤ºç»§ç»­
"""
import sqlite3
import os

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from src.state import AgentState
from src.nodes import (
    decide_search, search_web, generate_answer, skip_search,
    local_rag_search, hybrid_search
)
from src.config import Config


def prepare_search(state: AgentState) -> AgentState:
    """
    å‡†å¤‡æœç´¢èŠ‚ç‚¹ï¼šè®¾ç½®å¾…ç¡®è®¤çš„æ“ä½œæè¿°

    è¿™ä¸ªèŠ‚ç‚¹åœ¨ interrupt å‰æ‰§è¡Œï¼Œå‘Šè¯‰ç”¨æˆ·å³å°†åšä»€ä¹ˆ
    """
    search_type = state.get("search_type", "none")
    query = state["current_query"]

    # æ ¹æ®æœç´¢ç±»å‹ç”Ÿæˆæ“ä½œæè¿°
    action_descriptions = {
        "local": f"ğŸ“š å³å°†åœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æœç´¢: '{query}'",
        "web": f"ğŸŒ å³å°†è¿›è¡Œç½‘ç»œæœç´¢: '{query}'",
        "hybrid": f"ğŸ”„ å³å°†è¿›è¡Œæ··åˆæœç´¢ï¼ˆæœ¬åœ°+ç½‘ç»œï¼‰: '{query}'",
        "none": f"ğŸ’­ æ— éœ€æœç´¢ï¼Œå°†ç›´æ¥å›ç­”: '{query}'"
    }

    state["pending_action"] = action_descriptions.get(
        search_type,
        f"â“ æœªçŸ¥æ“ä½œç±»å‹: {search_type}"
    )
    state["current_step"] = "â¸ï¸ ç­‰å¾…ç”¨æˆ·ç¡®è®¤..."

    return state


def route_after_confirm(state: AgentState) -> str:
    """
    ç¡®è®¤åçš„è·¯ç”±å‡½æ•°

    æ ¹æ® search_type å†³å®šèµ°å“ªä¸ªæœç´¢èŠ‚ç‚¹
    """
    search_type = state.get("search_type", "none")

    routing = {
        "local": "local_rag",
        "web": "web_search",
        "hybrid": "hybrid_search",
        "none": "skip_search"
    }
    return routing.get(search_type, "skip_search")


def create_graph_with_interrupt():
    """
    åˆ›å»ºå¸¦ Human-in-the-loop çš„ Graph

    å…³é”®ç‚¹ï¼š
    1. æ·»åŠ  prepare_search èŠ‚ç‚¹ï¼Œè®¾ç½®å¾…ç¡®è®¤ä¿¡æ¯
    2. åœ¨æœç´¢èŠ‚ç‚¹å‰è®¾ç½® interrupt_before
    """
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("decide", decide_search)
    workflow.add_node("prepare", prepare_search)  # æ–°å¢ï¼šå‡†å¤‡ç¡®è®¤ä¿¡æ¯
    workflow.add_node("local_rag", local_rag_search)
    workflow.add_node("web_search", search_web)
    workflow.add_node("hybrid_search", hybrid_search)
    workflow.add_node("skip_search", skip_search)
    workflow.add_node("answer", generate_answer)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("decide")

    # decide â†’ prepareï¼ˆå…ˆå‡†å¤‡ç¡®è®¤ä¿¡æ¯ï¼‰
    workflow.add_edge("decide", "prepare")

    # prepare â†’ æ ¹æ®ç±»å‹è·¯ç”±åˆ°ä¸åŒæœç´¢èŠ‚ç‚¹
    workflow.add_conditional_edges(
        "prepare",
        route_after_confirm,
        {
            "local_rag": "local_rag",
            "web_search": "web_search",
            "hybrid_search": "hybrid_search",
            "skip_search": "skip_search"
        }
    )

    # æ‰€æœ‰æœç´¢èŠ‚ç‚¹ â†’ answer
    workflow.add_edge("local_rag", "answer")
    workflow.add_edge("web_search", "answer")
    workflow.add_edge("hybrid_search", "answer")
    workflow.add_edge("skip_search", "answer")
    workflow.add_edge("answer", END)

    # æŒä¹…åŒ–
    os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)
    conn = sqlite3.connect(
        f"{Config.CHECKPOINT_DIR}/checkpoints_interrupt.db",
        check_same_thread=False
    )
    memory = SqliteSaver(conn)

    # å…³é”®ï¼šè®¾ç½® interrupt_before
    # åœ¨è¿™äº›èŠ‚ç‚¹æ‰§è¡Œå‰ä¼šæš‚åœï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤
    return workflow.compile(
        checkpointer=memory,
        interrupt_before=["local_rag", "web_search", "hybrid_search"]
        # æ³¨æ„ï¼šskip_search ä¸éœ€è¦ç¡®è®¤
    )


# åˆ›å»ºå…¨å±€å®ä¾‹
graph_with_interrupt = create_graph_with_interrupt()


# ============ ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”§ Human-in-the-loop æ¼”ç¤º")
    print("=" * 60)

    config = {"configurable": {"thread_id": "interrupt-demo"}}

    # åˆå§‹çŠ¶æ€
    state = {
        "current_query": "ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ",
        "messages": [],
        "need_search": False,
        "search_results": "",
        "final_answer": "",
        "current_step": "",
        "search_type": "",
        "local_contexts": "",
        "sources": [],
        "human_approved": False,
        "pending_action": ""
    }

    print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {state['current_query']}")
    print("-" * 40)

    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šä¼šåœ¨æœç´¢å‰æš‚åœ
    print("\nğŸ“¤ ç¬¬ä¸€æ¬¡è°ƒç”¨ graph.invoke()...")
    result = graph_with_interrupt.invoke(state, config)

    print(f"\nâ¸ï¸ Graph æš‚åœ!")
    print(f"   æœç´¢ç±»å‹: {result.get('search_type', 'unknown')}")
    print(f"   å¾…ç¡®è®¤æ“ä½œ: {result.get('pending_action', 'N/A')}")

    # æ¨¡æ‹Ÿç”¨æˆ·ç¡®è®¤
    user_input = input("\næ˜¯å¦ç»§ç»­æ‰§è¡Œ? (y/n): ").strip().lower()

    if user_input == 'y':
        print("\nğŸ“¤ ç”¨æˆ·ç¡®è®¤ï¼Œç»§ç»­æ‰§è¡Œ...")
        # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šä¼  None è¡¨ç¤ºç»§ç»­æ‰§è¡Œ
        result = graph_with_interrupt.invoke(None, config)
        print(f"\nâœ… æ‰§è¡Œå®Œæˆ!")
        print(f"   æœ€ç»ˆç­”æ¡ˆ: {result.get('final_answer', 'N/A')[:200]}...")
    else:
        print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
