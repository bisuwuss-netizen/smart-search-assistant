"""
å¸¦åæ€å¾ªç¯çš„ Agentic RAG Graph

æ ¸å¿ƒç‰¹ç‚¹ï¼š
1. Reflector èŠ‚ç‚¹ï¼šLLM è¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿ
2. å¾ªç¯æœºåˆ¶ï¼šå¦‚æœä¸è¶³ï¼Œè‡ªåŠ¨æ”¹è¿›æŸ¥è¯¢å¹¶é‡æ–°æœç´¢
3. æœ€å¤§å¾ªç¯é™åˆ¶ï¼šé˜²æ­¢æ— é™å¾ªç¯ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰

æµç¨‹å›¾ï¼š
    ç”¨æˆ·è¾“å…¥ â†’ decide â†’ search â†’ reflector â†’ [åˆ¤æ–­]
                          â†‘                      â”‚
                          â”‚ insufficient         â”‚ sufficient
                          â””â”€â”€â”€â”€ refine â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â†“
                                              answer â†’ è¾“å‡º

è¿™æ˜¯ Agentic RAG çš„æ ¸å¿ƒè¿›é˜¶ç‚¹ï¼Œä½“ç°äº† Agent çš„"è‡ªä¸»å†³ç­–"èƒ½åŠ›ã€‚
"""
import sqlite3
import os

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from src.state import AgentState
from src.nodes import (
    decide_search, search_web, generate_answer, skip_search,
    local_rag_search, hybrid_search, reflect_on_results, refine_search
)
from src.config import Config


def route_search(state: AgentState) -> str:
    """è·¯ç”±åˆ°ä¸åŒçš„æœç´¢èŠ‚ç‚¹"""
    search_type = state.get("search_type", "none")
    routing = {
        "local": "local_rag",
        "web": "web_search",
        "hybrid": "hybrid_search",
        "none": "skip_search"
    }
    return routing.get(search_type, "skip_search")


def route_after_reflection(state: AgentState) -> str:
    """
    åæ€åçš„è·¯ç”±å†³ç­–

    è¿”å›å€¼ï¼š
    - "answer": ç»“æœå……åˆ†ï¼Œç”Ÿæˆç­”æ¡ˆ
    - "refine": ç»“æœä¸è¶³ï¼Œéœ€è¦æ”¹è¿›æœç´¢
    - "answer": è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œå¼ºåˆ¶ç”Ÿæˆç­”æ¡ˆ
    """
    reflection_result = state.get("reflection_result", "sufficient")
    loop_count = state.get("loop_count", 0)
    max_loops = state.get("max_loops", 3)

    # è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
    if loop_count >= max_loops:
        print(f"  âš ï¸ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° ({max_loops})ï¼Œå¼ºåˆ¶ç”Ÿæˆç­”æ¡ˆ")
        return "answer"

    # æ ¹æ®åæ€ç»“æœå†³å®š
    if reflection_result == "sufficient":
        return "answer"
    elif reflection_result == "insufficient":
        return "refine"
    else:  # irrelevant
        # ä¸ç›¸å…³çš„ç»“æœï¼Œå°è¯•æ”¹è¿›ä¸€æ¬¡
        if loop_count < 2:
            return "refine"
        return "answer"


def create_graph_with_reflection():
    """
    åˆ›å»ºå¸¦åæ€å¾ªç¯çš„ Graph

    è¿™æ˜¯é¡¹ç›®çš„æ ¸å¿ƒäº®ç‚¹ï¼Œä½“ç°äº†ï¼š
    1. Agentic RAG çš„è‡ªä¸»å†³ç­–èƒ½åŠ›
    2. LangGraph çš„å¾ªç¯ï¼ˆLoopï¼‰æœºåˆ¶
    3. è´¨é‡ä¿è¯çš„è‡ªåŠ¨åŒ–
    """
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("decide", decide_search)
    workflow.add_node("local_rag", local_rag_search)
    workflow.add_node("web_search", search_web)
    workflow.add_node("hybrid_search", hybrid_search)
    workflow.add_node("skip_search", skip_search)
    workflow.add_node("reflector", reflect_on_results)  # åæ€èŠ‚ç‚¹
    workflow.add_node("refine", refine_search)          # æ”¹è¿›æœç´¢èŠ‚ç‚¹
    workflow.add_node("answer", generate_answer)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("decide")

    # decide â†’ æ ¹æ®ç±»å‹è·¯ç”±åˆ°æœç´¢èŠ‚ç‚¹
    workflow.add_conditional_edges(
        "decide",
        route_search,
        {
            "local_rag": "local_rag",
            "web_search": "web_search",
            "hybrid_search": "hybrid_search",
            "skip_search": "skip_search"
        }
    )

    # æ‰€æœ‰æœç´¢èŠ‚ç‚¹ â†’ reflectorï¼ˆåæ€è¯„ä¼°ï¼‰
    workflow.add_edge("local_rag", "reflector")
    workflow.add_edge("web_search", "reflector")
    workflow.add_edge("hybrid_search", "reflector")

    # skip_search ä¸éœ€è¦åæ€ï¼Œç›´æ¥ç”Ÿæˆç­”æ¡ˆ
    workflow.add_edge("skip_search", "answer")

    # reflector â†’ æ¡ä»¶è·¯ç”±ï¼ˆå¾ªç¯çš„å…³é”®ï¼‰
    workflow.add_conditional_edges(
        "reflector",
        route_after_reflection,
        {
            "answer": "answer",
            "refine": "refine"
        }
    )

    # refine â†’ reflectorï¼ˆå½¢æˆå¾ªç¯ï¼‰
    workflow.add_edge("refine", "reflector")

    # answer â†’ END
    workflow.add_edge("answer", END)

    # æŒä¹…åŒ–
    os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)
    conn = sqlite3.connect(
        f"{Config.CHECKPOINT_DIR}/checkpoints_reflection.db",
        check_same_thread=False
    )
    memory = SqliteSaver(conn)

    return workflow.compile(checkpointer=memory)


# åˆ›å»ºå…¨å±€å®ä¾‹
graph_with_reflection = create_graph_with_reflection()


# ============ ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”„ Agentic RAG with Reflection Loop æ¼”ç¤º")
    print("=" * 60)
    print("""
è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº† Reflector + Loop æœºåˆ¶ï¼š
- Agent ä¼šè¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿ
- å¦‚æœä¸è¶³ï¼Œä¼šè‡ªåŠ¨æ”¹è¿›æŸ¥è¯¢å¹¶é‡æ–°æœç´¢
- æœ€å¤šå¾ªç¯ 3 æ¬¡ï¼Œç¡®ä¿ä¸ä¼šæ— é™å¾ªç¯
""")

    config = {"configurable": {"thread_id": "reflection-demo"}}

    # æµ‹è¯•é—®é¢˜
    questions = [
        "LangGraph çš„ checkpointer æœ‰å“ªäº›å®ç°ï¼Ÿ",
        "2024å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–çš„å…·ä½“è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    for question in questions:
        print("\n" + "=" * 60)
        print(f"â“ é—®é¢˜: {question}")
        print("=" * 60)

        # åˆå§‹çŠ¶æ€
        state = {
            "current_query": question,
            "messages": [],
            "need_search": False,
            "search_results": "",
            "final_answer": "",
            "current_step": "",
            "search_type": "",
            "local_contexts": "",
            "sources": [],
            "human_approved": False,
            "pending_action": "",
            # Reflector ç›¸å…³
            "reflection_result": "",
            "reflection_reason": "",
            "loop_count": 0,
            "max_loops": 3,
            "refined_query": ""
        }

        result = graph_with_reflection.invoke(state, config)

        print(f"\nğŸ‰ æœ€ç»ˆç»“æœ:")
        print(f"   å¾ªç¯æ¬¡æ•°: {result.get('loop_count', 0)}")
        print(f"   åæ€ç»“æœ: {result.get('reflection_result', 'N/A')}")
        print(f"   ç­”æ¡ˆé¢„è§ˆ: {result.get('final_answer', 'N/A')[:300]}...")

        # æ˜¾ç¤ºæ¥æº
        sources = result.get('sources', [])
        if sources:
            print(f"\n   ğŸ“š ä¿¡æ¯æ¥æº ({len(sources)} æ¡):")
            for i, src in enumerate(sources[:5], 1):
                print(f"      [{i}] {src.get('type', '?')}: {src.get('source', 'N/A')[:50]}")

        # æ›´æ¢ thread_id
        config = {"configurable": {"thread_id": f"reflection-{hash(question)}"}}
