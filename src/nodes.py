from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from src.state import AgentState
from src.config import Config
from src.tools import create_search_tool
from src.rag.rag_manager import RAGManager
from src.utils.llm_factory import LLMFactory

# åˆå§‹åŒ– LLM
llm = LLMFactory.get_model()

# æœç´¢å·¥å…·
search_tool = create_search_tool()

# åˆå§‹åŒ– RAG ç®¡ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼‰
_rag_manager = None

def get_rag_manager():
    """å»¶è¿Ÿè·å– RAG ç®¡ç†å™¨å®ä¾‹"""
    global _rag_manager
    if _rag_manager is None:
        _rag_manager = RAGManager.get_instance()
    return _rag_manager


def decide_search(state: AgentState) -> AgentState:
    """åˆ¤æ–­æœç´¢ç±»å‹å’Œå¤æ‚åº¦(æ ¹æ®å¤æ‚åº¦å†³å®šæ˜¯å¦å¼€å¯multi-query)"""
    state['current_step'] = "ğŸ¤” æ­£åœ¨åˆ¤æ–­æŸ¥è¯¢ç±»å‹..."
    query = state["current_query"]

    # æç¤ºè¯ä¼˜åŒ–ï¼šåŒæ—¶åˆ¤æ–­ç±»å‹å’Œå¤æ‚åº¦
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è·¯ç”±ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜ï¼Œå¹¶å†³å®šæœç´¢ç±»å‹å’Œé—®é¢˜å¤æ‚åº¦ã€‚

## é—®é¢˜
{query}

## è¯„ä¼°æ ‡å‡†
1. **æœç´¢ç±»å‹**ï¼š
   - LOCAL: æ¶‰åŠç‰¹å®šç§æœ‰çŸ¥è¯†ã€ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹
   - WEB: éœ€è¦äº’è”ç½‘ä¸Šçš„æœ€æ–°æ¶ˆæ¯ã€å¹¿åŸŸçŸ¥è¯†ã€äº‹å®æ ¸æŸ¥
   - HYBRID: æ—¢éœ€è¦æœ¬åœ°çŸ¥è¯†ï¼Œä¹Ÿéœ€è¦ç½‘ç»œè¡¥å……ä¿¡æ¯
   - NONE: é—²èŠã€ç®€å•å¸¸è¯†ã€å¯ä»¥ç›´æ¥å›ç­”æ— éœ€æœç´¢

2. **å¤æ‚åº¦**ï¼š
   - SIMPLE: äº‹å®æ€§å•ä¸€é—®é¢˜ï¼Œæ„å›¾æ˜ç¡®ï¼Œæ— æ­§ä¹‰ï¼ˆä¾‹å¦‚ï¼šâ€œè°æ˜¯è‹¹æœå…¬å¸çš„ CEOï¼Ÿâ€ï¼‰
   - COMPLEX: æ¶‰åŠå¯¹æ¯”ã€åˆ†æã€å¤šæ­¥é€»è¾‘ã€å¹¿æ³›é¢†åŸŸæˆ–å­˜åœ¨æ½œåœ¨æ­§ä¹‰çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šâ€œåˆ†ææ•°å­—ç»æµå¯¹ä¸­äºšå›½å®¶çš„å½±å“â€ï¼‰

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™æ–‡å­—ï¼‰
TYPE: [LOCAL/WEB/HYBRID/NONE]
COMPLEXITY: [SIMPLE/COMPLEX]

åˆ†æç»“è®ºï¼š"""

    response = llm.invoke([HumanMessage(content=prompt)])
    content = response.content.strip()

    # è§£æç»“æœ
    search_type = "WEB"
    complexity = "SIMPLE"
    
    for line in content.split("\n"):
        if "TYPE:" in line:
            search_type = line.split(":", 1)[1].strip().upper()
        if "COMPLEXITY:" in line:
            complexity = line.split(":", 1)[1].strip().upper()

    # éªŒè¯ä¸å®¹é”™
    if search_type not in ["LOCAL", "WEB", "HYBRID", "NONE"]:
        search_type = "WEB"
    
    state["search_type"] = search_type.lower()
    
    # åŠ¨æ€ç¡®å®šæ˜¯å¦æ‰§è¡Œ Multi-Query
    # é€»è¾‘ï¼šåªæœ‰å½“å¤æ‚åº¦ä¸º COMPLEX ä¸”ç”¨æˆ·æ²¡åœ¨å…¥å£å¤„æ˜¾å¼ç¦ç”¨æ—¶ï¼Œæ‰å¼€å¯æ‰©å±•
    if state.get("use_multi_query", True):
        state["use_multi_query"] = (complexity == "COMPLEX")
    
    print(f"  ğŸ¯ æ„å›¾è¯†åˆ«: ç±»å‹={search_type} | å¤æ‚åº¦={complexity} | Multi-Query={state['use_multi_query']}")
    return state


def expand_query(state: AgentState) -> AgentState:
    """
    Multi-Query æŸ¥è¯¢æ‰©å±•èŠ‚ç‚¹

    å°†å•ä¸ªé—®é¢˜æ‰©å±•ä¸ºå¤šä¸ªç›¸å…³æŸ¥è¯¢ï¼Œæé«˜æ£€ç´¢å¬å›ç‡ã€‚
    è¿™æ˜¯ RAG ä¼˜åŒ–çš„é‡è¦æŠ€æœ¯ï¼Œå¯ä»¥ï¼š
    1. æ•æ‰é—®é¢˜çš„ä¸åŒè¡¨è¿°æ–¹å¼
    2. è¦†ç›–ç›¸å…³çš„å­é—®é¢˜
    3. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ç»„åˆ
    """
    state["current_step"] = "ğŸ”„ æ­£åœ¨æ‰©å±•æŸ¥è¯¢é—®é¢˜..."

    # å¦‚æœç¦ç”¨äº† Multi-Queryï¼Œç›´æ¥è¿”å›åŸæŸ¥è¯¢
    if not state.get("use_multi_query", True):
        state["expanded_queries"] = [state["current_query"]]
        return state

    query = state["current_query"]

    expand_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ‰©å±•ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„é—®é¢˜æ‰©å±•ä¸º 3-4 ä¸ªç›¸å…³ä½†ä¸åŒè§’åº¦çš„æœç´¢æŸ¥è¯¢ã€‚

## ç”¨æˆ·åŸå§‹é—®é¢˜
{query}

## æ‰©å±•è¦æ±‚
1. ä¿ç•™åŸå§‹é—®é¢˜çš„æ ¸å¿ƒæ„å›¾
2. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯å’Œè¡¨è¿°æ–¹å¼
3. å¯ä»¥åŒ…å«ç›¸å…³çš„å­é—®é¢˜
4. æ¯ä¸ªæŸ¥è¯¢éƒ½åº”è¯¥æ˜¯ç‹¬ç«‹çš„ã€å¯æœç´¢çš„

## è¾“å‡ºæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼Œä¸è¦ç¼–å·ï¼‰
æŸ¥è¯¢1
æŸ¥è¯¢2
æŸ¥è¯¢3
æŸ¥è¯¢4

è¯·æ‰©å±•ï¼š"""

    response = llm.invoke([HumanMessage(content=expand_prompt)])
    result_text = response.content.strip()

    # è§£ææ‰©å±•çš„æŸ¥è¯¢
    expanded = []
    for line in result_text.split("\n"):
        line = line.strip()
        # è·³è¿‡ç©ºè¡Œå’Œç¼–å·
        if line and not line.startswith("#") and len(line) > 5:
            # å»é™¤å¯èƒ½çš„ç¼–å·å‰ç¼€ (1. 2. ç­‰)
            if line[0].isdigit() and (line[1] == '.' or line[1] == 'ã€'):
                line = line[2:].strip()
            expanded.append(line)

    # ç¡®ä¿è‡³å°‘æœ‰åŸå§‹æŸ¥è¯¢
    if not expanded:
        expanded = [query]
    else:
        # é™åˆ¶æœ€å¤š 4 ä¸ªæŸ¥è¯¢
        expanded = expanded[:4]
        # ç¡®ä¿åŸå§‹æŸ¥è¯¢åœ¨åˆ—è¡¨ä¸­
        if query not in expanded:
            expanded.insert(0, query)

    state["expanded_queries"] = expanded

    print(f"  ğŸ“ åŸå§‹æŸ¥è¯¢: {query}")
    print(f"  ğŸ”„ æ‰©å±•æŸ¥è¯¢ ({len(expanded)} ä¸ª):")
    for i, q in enumerate(expanded, 1):
        print(f"     {i}. {q}")

    return state


def local_rag_search(state: AgentState) -> AgentState:
    """
    æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢

    æ”¯æŒ Multi-Queryï¼šå¦‚æœæœ‰æ‰©å±•æŸ¥è¯¢ï¼Œä¼šå¯¹æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæ£€ç´¢å¹¶åˆå¹¶ç»“æœ
    """
    state["current_step"] = "ğŸ“š æ­£åœ¨æ£€ç´¢æœ¬åœ°çŸ¥è¯†åº“..."

    # è·å–æŸ¥è¯¢åˆ—è¡¨ï¼ˆæ”¯æŒ Multi-Queryï¼‰
    queries = state.get("expanded_queries", [state["current_query"]])
    if not queries:
        queries = [state["current_query"]]

    all_contexts = []
    all_sources = []
    seen_contents = set()  # ç”¨äºå»é‡

    for query in queries:
        result = get_rag_manager().query(query, top_n=3)  # æ¯ä¸ªæŸ¥è¯¢å– top 3

        for ctx in result["contexts"]:
            content = ctx.get("content", "")
            # ç®€å•å»é‡ï¼šè·³è¿‡é‡å¤å†…å®¹
            content_hash = hash(content[:100])
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                all_contexts.append(ctx)
                all_sources.append({
                    "type": "local",
                    "source": ctx.get("metadata", {}).get("source", ""),
                    "score": float(ctx.get("score", 0))
                })

    # æŒ‰åˆ†æ•°æ’åºï¼Œå– top 5
    all_contexts.sort(key=lambda x: x.get("score", 0), reverse=True)
    all_contexts = all_contexts[:5]
    all_sources = all_sources[:5]

    # æ ¼å¼åŒ–ç»“æœ
    state["local_contexts"] = _format_local_contexts(all_contexts)
    state["sources"] = all_sources

    print(f"  ğŸ“š æ£€ç´¢åˆ° {len(all_contexts)} æ¡æœ¬åœ°ç»“æœ")
    return state


def _format_local_contexts(contexts: list) -> str:
    """æ ¼å¼åŒ–æœ¬åœ°æ£€ç´¢ç»“æœ"""
    if not contexts:
        return "## æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ\n\næœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"

    import os
    result = "## æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ\n\n"
    for i, ctx in enumerate(contexts, 1):
        source = ctx.get('metadata', {}).get('source', 'æœªçŸ¥æ¥æº')
        if source and source != 'æœªçŸ¥æ¥æº':
            source = os.path.basename(source)
        score = ctx.get('score', 0)
        result += f"[{i}] æ¥æº: {source} (ç›¸å…³åº¦: {score:.2f})\n"
        result += f"å†…å®¹: {ctx.get('content', '')}\n\n"
    return result


def hybrid_search(state: AgentState) -> AgentState:
    """æ··åˆæœç´¢ï¼šæœ¬åœ° + ç½‘ç»œ (æ”¯æŒ Multi-Query)"""
    state["current_step"] = "ğŸ”„ æ­£åœ¨è¿›è¡Œæ··åˆæœç´¢..."
    
    queries = state.get("expanded_queries", [state["current_query"]])
    
    # 1. æœ¬åœ°æ£€ç´¢ (å–å…¨é‡ queries)
    all_local_contexts = []
    seen_local = set()
    for q in queries:
        local_result = get_rag_manager().query(q, top_n=3)
        for ctx in local_result["contexts"]:
            content_hash = hash(ctx.get("content", "")[:100])
            if content_hash not in seen_local:
                seen_local.add(content_hash)
                all_local_contexts.append(ctx)
    
    # 2. ç½‘ç»œæœç´¢ (å¹¶å‘æ‰§è¡Œæ‰€æœ‰ queries)
    from concurrent.futures import ThreadPoolExecutor
    all_web_results = []
    seen_urls = set()
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        batch_results = list(executor.map(search_tool.invoke, queries))
        
    for results in batch_results:
        # å¤„ç†ä¸åŒæ ¼å¼çš„è¿”å›ç»“æœ
        search_hits = []
        if isinstance(results, list):
            search_hits = results
        elif isinstance(results, dict):
            # Tavily ç­‰å¯èƒ½è¿”å› {"results": [...]} æˆ– {"answer": ...}
            search_hits = results.get("results", [])
            if not search_hits and "answer" in results:
                search_hits = [{"content": results["answer"], "url": "Tavily Answer"}]
        elif isinstance(results, str):
            search_hits = [{"content": results, "url": "N/A"}]
            
        for r in search_hits:
            url = r.get("url", r.get("link", "N/A"))
            if url not in seen_urls:
                seen_urls.add(url)
                all_web_results.append(r)

    # æ ¼å¼åŒ–
    state["local_contexts"] = _format_local_contexts(all_local_contexts[:5])
    state["search_results"] = "\n\n".join([
        f"[ç½‘ç»œ{i+1}] æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹: {r.get('content', '')}"
        for i, r in enumerate(all_web_results[:5])
    ])
    
    # åˆå¹¶æ¥æº
    state["sources"] = [
        {"type": "local", "source": ctx.get("metadata", {}).get("source", ""), "score": float(ctx.get("score", 0))}
        for ctx in all_local_contexts[:3]
    ] + [
        {"type": "web", "source": r.get("url", ""), "score": 1.0}
        for r in all_web_results[:3]
    ]
    
    return state


def generate_answer(state: AgentState) -> AgentState:
    """ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ"""
    state["current_step"] = "âœï¸ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."
    
    query = state["current_query"]
    search_type = state.get("search_type", "none")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    if state.get("local_contexts"):
        context_parts.append(state["local_contexts"])
    if state.get("search_results"):
        context_parts.append("## ç½‘ç»œæœç´¢ç»“æœ\n" + state["search_results"])
    
    context = "\n\n".join(context_parts) if context_parts else ""
    
    if context:
        prompt = f"""åŸºäºä»¥ä¸‹æ£€ç´¢ç»“æœå›ç­”é—®é¢˜ï¼š

{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¦æ±‚
1. ç»¼åˆæœ¬åœ°çŸ¥è¯†åº“å’Œç½‘ç»œä¿¡æ¯å›ç­”
2. ä½¿ç”¨ [æ¥æºN] æ ¼å¼æ ‡æ³¨å¼•ç”¨
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜"""
    else:
        prompt = f"å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}"
    
    messages = state["messages"] + [HumanMessage(content=prompt)]
    response = llm.invoke(messages)
    
    state["final_answer"] = response.content
    state["current_step"] = "âœ… å®Œæˆ"
    
    # æ›´æ–°å¯¹è¯å†å²
    state["messages"].append(HumanMessage(content=query))
    state["messages"].append(AIMessage(content=response.content))
    
    return state


def search_web(state: AgentState) -> AgentState:
    """ç½‘ç»œæœç´¢èŠ‚ç‚¹ (æ”¯æŒ Multi-Query)"""
    state["current_step"] = "ğŸ” æ­£åœ¨æœç´¢ç½‘ç»œ..."

    queries = state.get("expanded_queries") or [state["current_query"]]
    
    # å¹¶å‘æœç´¢
    from concurrent.futures import ThreadPoolExecutor
    all_results = []
    seen_urls = set()
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        batch_results = list(executor.map(search_tool.invoke, queries))
        
    for results in batch_results:
        # å¤„ç†ä¸åŒæ ¼å¼çš„è¿”å›ç»“æœ
        search_hits = []
        if isinstance(results, list):
            search_hits = results
        elif isinstance(results, dict):
            # Tavily ç­‰å¯èƒ½è¿”å› {"results": [...]} æˆ– {"answer": ...}
            search_hits = results.get("results", [])
            if not search_hits and "answer" in results:
                search_hits = [{"content": results["answer"], "url": "Tavily Answer"}]
        elif isinstance(results, str):
            search_hits = [{"content": results, "url": "N/A"}]
            
        for r in search_hits:
            url = r.get("url", r.get("link", "N/A"))
            if url not in seen_urls:
                seen_urls.add(url)
                all_results.append(r)

    # æ ¼å¼åŒ–ç»“æœ (å–å‰ 8 æ¡ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿)
    formatted = "\n\n".join([
        f"æ¥æº {i + 1}: {r.get('url', 'N/A')}\næœç´¢å†…å®¹ï¼š{r.get('content', r.get('snippet', ''))}"
        for i, r in enumerate(all_results[:8])
    ])

    state["search_results"] = formatted
    
    # æ›´æ–° sources
    state["sources"] = [
        {"type": "web", "source": r.get("url", "N/A"), "score": 1.0}
        for r in all_results[:5]
    ]
    
    print(f"  ğŸŒ ç½‘ç»œæ£€ç´¢å®Œæˆ: å…± {len(queries)} ä¸ªæŸ¥è¯¢, å¾—åˆ° {len(all_results)} æ¡å»é‡ç»“æœ")
    return state


def skip_search(state: AgentState) -> AgentState:
    """è·³è¿‡æœç´¢çš„èŠ‚ç‚¹ï¼ˆç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼‰"""
    state["current_step"] = "ğŸ’­ æ— éœ€æœç´¢ï¼Œç›´æ¥å›ç­”..."
    return state


def reflect_on_results(state: AgentState) -> AgentState:
    """
    åæ€èŠ‚ç‚¹ï¼šè¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜

    è¿™æ˜¯ Agentic RAG çš„å…³é”®è¿›é˜¶ç‚¹ï¼š
    - LLM è¯„ä¼°æ£€ç´¢åˆ°çš„ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿã€æ˜¯å¦ç›¸å…³
    - å¦‚æœä¸è¶³ï¼Œç”Ÿæˆæ”¹è¿›çš„æŸ¥è¯¢å¹¶è§¦å‘é‡æ–°æœç´¢
    - æœ€å¤šå¾ªç¯ max_loops æ¬¡ï¼Œé˜²æ­¢æ— é™å¾ªç¯
    """
    state["current_step"] = "ğŸ¤” æ­£åœ¨è¯„ä¼°æ£€ç´¢ç»“æœ..."

    query = state["current_query"]
    loop_count = state.get("loop_count", 0)
    max_loops = state.get("max_loops", 3)

    # æ”¶é›†æ‰€æœ‰æ£€ç´¢ç»“æœ
    context_parts = []
    if state.get("local_contexts"):
        context_parts.append(f"æœ¬åœ°çŸ¥è¯†åº“ç»“æœ:\n{state['local_contexts']}")
    if state.get("search_results"):
        context_parts.append(f"ç½‘ç»œæœç´¢ç»“æœ:\n{state['search_results']}")

    all_contexts = "\n\n".join(context_parts) if context_parts else "æ— æ£€ç´¢ç»“æœ"

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœï¼Œç›´æ¥æ ‡è®°ä¸ºä¸è¶³
    if not context_parts:
        state["reflection_result"] = "insufficient"
        state["reflection_reason"] = "æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•ç»“æœ"
        state["loop_count"] = loop_count + 1
        return state

    # è®© LLM è¯„ä¼°ç»“æœè´¨é‡
    reflect_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æ£€ç´¢ç»“æœæ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

## ç”¨æˆ·é—®é¢˜
{query}

## æ£€ç´¢ç»“æœ
{all_contexts[:3000]}  # é™åˆ¶é•¿åº¦é¿å… token è¿‡å¤š

## è¯„ä¼°æ ‡å‡†
1. SUFFICIENTï¼ˆå……åˆ†ï¼‰ï¼šæ£€ç´¢ç»“æœç›´æ¥å›ç­”äº†é—®é¢˜ï¼Œä¿¡æ¯å®Œæ•´ã€ç›¸å…³
2. INSUFFICIENTï¼ˆä¸è¶³ï¼‰ï¼šæ£€ç´¢ç»“æœç›¸å…³ä½†ä¸å®Œæ•´ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯
3. IRRELEVANTï¼ˆä¸ç›¸å…³ï¼‰ï¼šæ£€ç´¢ç»“æœä¸é—®é¢˜æ— å…³

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼‰
RESULT: [SUFFICIENT/INSUFFICIENT/IRRELEVANT]
REASON: [ä¸€å¥è¯è¯´æ˜åŸå› ]
REFINED_QUERY: [å¦‚æœæ˜¯ INSUFFICIENTå’ŒIRRELEVANTï¼Œç»™å‡ºæ”¹è¿›çš„æœç´¢æŸ¥è¯¢ï¼›å¦åˆ™ç•™ç©º]

è¯·è¯„ä¼°ï¼š"""

    response = llm.invoke([HumanMessage(content=reflect_prompt)])
    result_text = response.content.strip()

    # è§£æ LLM è¾“å‡º
    reflection_result = "sufficient"  # é»˜è®¤å……åˆ†
    reflection_reason = ""
    refined_query = ""

    for line in result_text.split("\n"):
        line = line.strip()
        if line.startswith("RESULT:"):
            result_value = line.replace("RESULT:", "").strip().upper()
            if result_value in ["SUFFICIENT", "INSUFFICIENT", "IRRELEVANT"]:
                reflection_result = result_value.lower()
        elif line.startswith("REASON:"):
            reflection_reason = line.replace("REASON:", "").strip()
        elif line.startswith("REFINED_QUERY:"):
            refined_query = line.replace("REFINED_QUERY:", "").strip()

    # æ›´æ–°çŠ¶æ€
    state["reflection_result"] = reflection_result
    state["reflection_reason"] = reflection_reason
    state["refined_query"] = refined_query if refined_query else query
    state["loop_count"] = loop_count + 1

    # æ‰“å°åæ€ç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"  ğŸ” åæ€ç»“æœ: {reflection_result}")
    print(f"  ğŸ“ åŸå› : {reflection_reason}")
    if reflection_result == "insufficient" and refined_query:
        print(f"  ğŸ”„ æ”¹è¿›æŸ¥è¯¢: {refined_query}")
    print(f"  ğŸ“Š å½“å‰å¾ªç¯: {state['loop_count']}/{max_loops}")

    return state


def refine_search(state: AgentState) -> AgentState:
    """
    æ”¹è¿›æœç´¢èŠ‚ç‚¹ï¼šä½¿ç”¨æ”¹è¿›åçš„æŸ¥è¯¢é‡æ–°æœç´¢

    å½“ Reflector åˆ¤æ–­ç»“æœä¸è¶³æ—¶ï¼Œç”¨æ”¹è¿›çš„æŸ¥è¯¢é‡æ–°æ£€ç´¢
    """
    state["current_step"] = "ğŸ”„ æ­£åœ¨ä½¿ç”¨æ”¹è¿›çš„æŸ¥è¯¢é‡æ–°æœç´¢..."

    refined_query = state.get("refined_query", state["current_query"])
    search_type = state.get("search_type", "web")

    print(f"  ğŸ”„ æ”¹è¿›æœç´¢: {refined_query}")

    # æ ¹æ®æœç´¢ç±»å‹æ‰§è¡Œæœç´¢
    if search_type == "local":
        result = get_rag_manager().query(refined_query, top_n=5)
        # è¿½åŠ åˆ°ç°æœ‰ç»“æœ
        existing = state.get("local_contexts", "")
        state["local_contexts"] = existing + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + result["formatted"]
        # è¿½åŠ æ¥æº
        new_sources = [
            {"type": "local", "source": ctx.get("metadata", {}).get("source", ""), "score": float(ctx.get("score", 0))}
            for ctx in result["contexts"]
        ]
        state["sources"] = state.get("sources", []) + new_sources

    elif search_type == "web":
        results = search_tool.invoke(refined_query)
        if isinstance(results, list):
            formatted = "\n\n".join([
                f"æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹ï¼š{r.get('content', '')}"
                for r in results
            ])
        else:
            formatted = str(results)
        existing = state.get("search_results", "")
        state["search_results"] = existing + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + formatted

    elif search_type == "hybrid":
        # æ··åˆæœç´¢
        local_result = get_rag_manager().query(refined_query, top_n=3)
        web_results = search_tool.invoke(refined_query)

        existing_local = state.get("local_contexts", "")
        state["local_contexts"] = existing_local + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + local_result["formatted"]

        if isinstance(web_results, list):
            formatted_web = "\n\n".join([
                f"æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹: {r.get('content', '')}"
                for r in web_results
            ])
        else:
            formatted_web = str(web_results)
        existing_web = state.get("search_results", "")
        state["search_results"] = existing_web + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + formatted_web

    return state