from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from src.state import AgentState
from src.config import Config
from src.tools import create_search_tool
from src.rag.rag_manager import RAGManager
from src.utils.llm_factory import LLMFactory

# åˆå§‹åŒ– LLM
llm = LLMFactory.get_model()

# æœç´¢å·¥å…·
search_tool = create_search_tool()

# åˆå§‹åŒ– RAG ç®¡ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼‰
_rag_manager = None

def get_rag_manager():
    """å»¶è¿Ÿè·å– RAG ç®¡ç†å™¨å®ä¾‹"""
    global _rag_manager
    if _rag_manager is None:
        _rag_manager = RAGManager.get_instance()
    return _rag_manager


def decide_search(state: AgentState) -> AgentState:
    """åˆ¤æ–­æœç´¢ç±»å‹ï¼šlocal / web / hybrid / none"""
    query = state["current_query"]

    prompt = f"""åˆ¤æ–­ä»¥ä¸‹é—®é¢˜åº”è¯¥ä½¿ç”¨å“ªç§æœç´¢æ–¹å¼ï¼š

é—®é¢˜ï¼š{query}

é€‰é¡¹ï¼š
- LOCAL: é—®é¢˜æ¶‰åŠå·²ä¸Šä¼ çš„æ–‡æ¡£/çŸ¥è¯†åº“å†…å®¹
- WEB: éœ€è¦æœ€æ–°ä¿¡æ¯ã€æ–°é—»ã€å®æ—¶æ•°æ®
- HYBRID: éœ€è¦ç»“åˆæœ¬åœ°çŸ¥è¯†å’Œç½‘ç»œä¿¡æ¯
- NONE: å¸¸è¯†é—®é¢˜ï¼Œæ— éœ€æœç´¢

åªå›ç­” LOCAL / WEB / HYBRID / NONE ä¹‹ä¸€ã€‚"""

    response = llm.invoke([HumanMessage(content=prompt)])
    search_type = response.content.strip().upper()

    # éªŒè¯è¿”å›å€¼
    if search_type not in ["LOCAL", "WEB", "HYBRID", "NONE"]:
        search_type = "WEB"  # é»˜è®¤ç½‘ç»œæœç´¢

    state["search_type"] = search_type.lower()
    return state


def expand_query(state: AgentState) -> AgentState:
    """
    Multi-Query æŸ¥è¯¢æ‰©å±•èŠ‚ç‚¹

    å°†å•ä¸ªé—®é¢˜æ‰©å±•ä¸ºå¤šä¸ªç›¸å…³æŸ¥è¯¢ï¼Œæé«˜æ£€ç´¢å¬å›ç‡ã€‚
    è¿™æ˜¯ RAG ä¼˜åŒ–çš„é‡è¦æŠ€æœ¯ï¼Œå¯ä»¥ï¼š
    1. æ•æ‰é—®é¢˜çš„ä¸åŒè¡¨è¿°æ–¹å¼
    2. è¦†ç›–ç›¸å…³çš„å­é—®é¢˜
    3. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ç»„åˆ
    """
    state["current_step"] = "ğŸ”„ æ­£åœ¨æ‰©å±•æŸ¥è¯¢..."

    # å¦‚æœç¦ç”¨äº† Multi-Queryï¼Œç›´æ¥è¿”å›åŸæŸ¥è¯¢
    if not state.get("use_multi_query", True):
        state["expanded_queries"] = [state["current_query"]]
        return state

    query = state["current_query"]

    expand_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ‰©å±•ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„é—®é¢˜æ‰©å±•ä¸º 3-4 ä¸ªç›¸å…³ä½†ä¸åŒè§’åº¦çš„æœç´¢æŸ¥è¯¢ã€‚

## ç”¨æˆ·åŸå§‹é—®é¢˜
{query}

## æ‰©å±•è¦æ±‚
1. ä¿ç•™åŸå§‹é—®é¢˜çš„æ ¸å¿ƒæ„å›¾
2. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯å’Œè¡¨è¿°æ–¹å¼
3. å¯ä»¥åŒ…å«ç›¸å…³çš„å­é—®é¢˜
4. æ¯ä¸ªæŸ¥è¯¢éƒ½åº”è¯¥æ˜¯ç‹¬ç«‹çš„ã€å¯æœç´¢çš„

## è¾“å‡ºæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼Œä¸è¦ç¼–å·ï¼‰
æŸ¥è¯¢1
æŸ¥è¯¢2
æŸ¥è¯¢3
æŸ¥è¯¢4

è¯·æ‰©å±•ï¼š"""

    response = llm.invoke([HumanMessage(content=expand_prompt)])
    result_text = response.content.strip()

    # è§£ææ‰©å±•çš„æŸ¥è¯¢
    expanded = []
    for line in result_text.split("\n"):
        line = line.strip()
        # è·³è¿‡ç©ºè¡Œå’Œç¼–å·
        if line and not line.startswith("#") and len(line) > 5:
            # å»é™¤å¯èƒ½çš„ç¼–å·å‰ç¼€ (1. 2. ç­‰)
            if line[0].isdigit() and (line[1] == '.' or line[1] == 'ã€'):
                line = line[2:].strip()
            expanded.append(line)

    # ç¡®ä¿è‡³å°‘æœ‰åŸå§‹æŸ¥è¯¢
    if not expanded:
        expanded = [query]
    else:
        # é™åˆ¶æœ€å¤š 4 ä¸ªæŸ¥è¯¢
        expanded = expanded[:4]
        # ç¡®ä¿åŸå§‹æŸ¥è¯¢åœ¨åˆ—è¡¨ä¸­
        if query not in expanded:
            expanded.insert(0, query)

    state["expanded_queries"] = expanded

    print(f"  ğŸ“ åŸå§‹æŸ¥è¯¢: {query}")
    print(f"  ğŸ”„ æ‰©å±•æŸ¥è¯¢ ({len(expanded)} ä¸ª):")
    for i, q in enumerate(expanded, 1):
        print(f"     {i}. {q}")

    return state


def local_rag_search(state: AgentState) -> AgentState:
    """
    æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢

    æ”¯æŒ Multi-Queryï¼šå¦‚æœæœ‰æ‰©å±•æŸ¥è¯¢ï¼Œä¼šå¯¹æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæ£€ç´¢å¹¶åˆå¹¶ç»“æœ
    """
    state["current_step"] = "ğŸ“š æ­£åœ¨æ£€ç´¢æœ¬åœ°çŸ¥è¯†åº“..."

    # è·å–æŸ¥è¯¢åˆ—è¡¨ï¼ˆæ”¯æŒ Multi-Queryï¼‰
    queries = state.get("expanded_queries", [state["current_query"]])
    if not queries:
        queries = [state["current_query"]]

    all_contexts = []
    all_sources = []
    seen_contents = set()  # ç”¨äºå»é‡

    for query in queries:
        result = get_rag_manager().query(query, top_n=3)  # æ¯ä¸ªæŸ¥è¯¢å– top 3

        for ctx in result["contexts"]:
            content = ctx.get("content", "")
            # ç®€å•å»é‡ï¼šè·³è¿‡é‡å¤å†…å®¹
            content_hash = hash(content[:100])
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                all_contexts.append(ctx)
                all_sources.append({
                    "type": "local",
                    "source": ctx.get("metadata", {}).get("source", ""),
                    "score": float(ctx.get("score", 0))
                })

    # æŒ‰åˆ†æ•°æ’åºï¼Œå– top 5
    all_contexts.sort(key=lambda x: x.get("score", 0), reverse=True)
    all_contexts = all_contexts[:5]
    all_sources = all_sources[:5]

    # æ ¼å¼åŒ–ç»“æœ
    state["local_contexts"] = _format_local_contexts(all_contexts)
    state["sources"] = all_sources

    print(f"  ğŸ“š æ£€ç´¢åˆ° {len(all_contexts)} æ¡æœ¬åœ°ç»“æœ")
    return state


def _format_local_contexts(contexts: list) -> str:
    """æ ¼å¼åŒ–æœ¬åœ°æ£€ç´¢ç»“æœ"""
    if not contexts:
        return "## æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ\n\næœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"

    import os
    result = "## æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç»“æœ\n\n"
    for i, ctx in enumerate(contexts, 1):
        source = ctx.get('metadata', {}).get('source', 'æœªçŸ¥æ¥æº')
        if source and source != 'æœªçŸ¥æ¥æº':
            source = os.path.basename(source)
        score = ctx.get('score', 0)
        result += f"[{i}] æ¥æº: {source} (ç›¸å…³åº¦: {score:.2f})\n"
        result += f"å†…å®¹: {ctx.get('content', '')}\n\n"
    return result


def hybrid_search(state: AgentState) -> AgentState:
    """æ··åˆæœç´¢ï¼šæœ¬åœ° + ç½‘ç»œ"""
    state["current_step"] = "ğŸ”„ æ­£åœ¨è¿›è¡Œæ··åˆæœç´¢..."
    
    # 1. æœ¬åœ°æ£€ç´¢
    local_result = get_rag_manager().query(state["current_query"], top_n=3)
    state["local_contexts"] = local_result["formatted"]
    
    # 2. ç½‘ç»œæœç´¢
    search_query = state["current_query"]
    web_results = search_tool.invoke(search_query)
    
    # æ ¼å¼åŒ–ç½‘ç»œç»“æœ
    if isinstance(web_results, list):
        formatted_web = "\n\n".join([
            f"[ç½‘ç»œ{i+1}] æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹: {r.get('content', '')}"
            for i, r in enumerate(web_results)
        ])
    else:
        formatted_web = str(web_results)
    
    state["search_results"] = formatted_web
    
    # åˆå¹¶æ¥æºï¼ˆå°† numpy.float32 è½¬æ¢ä¸º Python floatï¼‰
    state["sources"] = [
        {"type": "local", "source": ctx.get("metadata", {}).get("source", ""), "score": float(ctx.get("score", 0))}
        for ctx in local_result["contexts"]
    ] + [
        {"type": "web", "source": r.get("url", ""), "score": 1.0}
        for r in (web_results if isinstance(web_results, list) else [])
    ]
    
    return state


def generate_answer(state: AgentState) -> AgentState:
    """ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ"""
    state["current_step"] = "âœï¸ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."
    
    query = state["current_query"]
    search_type = state.get("search_type", "none")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    if state.get("local_contexts"):
        context_parts.append(state["local_contexts"])
    if state.get("search_results"):
        context_parts.append("## ç½‘ç»œæœç´¢ç»“æœ\n" + state["search_results"])
    
    context = "\n\n".join(context_parts) if context_parts else ""
    
    if context:
        prompt = f"""åŸºäºä»¥ä¸‹æ£€ç´¢ç»“æœå›ç­”é—®é¢˜ï¼š

{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¦æ±‚
1. ç»¼åˆæœ¬åœ°çŸ¥è¯†åº“å’Œç½‘ç»œä¿¡æ¯å›ç­”
2. ä½¿ç”¨ [æ¥æºN] æ ¼å¼æ ‡æ³¨å¼•ç”¨
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜"""
    else:
        prompt = f"å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}"
    
    messages = state["messages"] + [HumanMessage(content=prompt)]
    response = llm.invoke(messages)
    
    state["final_answer"] = response.content
    state["current_step"] = "âœ… å®Œæˆ"
    
    # æ›´æ–°å¯¹è¯å†å²
    state["messages"].append(HumanMessage(content=query))
    state["messages"].append(AIMessage(content=response.content))
    
    return state


def search_web(state: AgentState) -> AgentState:
    """ç½‘ç»œæœç´¢èŠ‚ç‚¹"""
    state["current_step"] = "ğŸ” æ­£åœ¨æœç´¢ç½‘ç»œ..."

    query = state["current_query"]
    # è¿™é‡Œéœ€è¦é‡å†™queryï¼Œé˜²æ­¢åç»­é—®åˆ°"å®ƒ"ç­‰ä»£è¯ï¼Œä¸çŸ¥é“æŒ‡ä»£çš„æ˜¯ä»€ä¹ˆ
    messages = state["messages"]
    if messages:  # æœ‰å†å²å¯¹è¯
        # è®© LLM åŸºäºå†å²é‡å†™æŸ¥è¯¢
        rewrite_prompt = f"""åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„æ–°é—®é¢˜æ”¹å†™ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ã€å®Œæ•´çš„æœç´¢æŸ¥è¯¢ã€‚
        å¯¹è¯å†å²ï¼š
        {chr(10).join([f"{msg.type}: {msg.content[:100]}" for msg in messages[-4:]])}
        ç”¨æˆ·æ–°é—®é¢˜ï¼š{query}
        è¦æ±‚ï¼š
        1. å¦‚æœé—®é¢˜åŒ…å«"å®ƒ"ã€"è¿™ä¸ª"ç­‰ä»£è¯ï¼Œæ›¿æ¢ä¸ºå…·ä½“äº‹ç‰©
        2. å¦‚æœé—®é¢˜æ˜¯è¿½é—®ï¼Œè¡¥å……å¿…è¦çš„ä¸Šä¸‹æ–‡
        3. åªè¾“å‡ºæ”¹å†™åçš„æœç´¢æŸ¥è¯¢ï¼Œä¸è¦è§£é‡Š
        æ”¹å†™åçš„æŸ¥è¯¢ï¼š"""

        #è°ƒç”¨ llm é‡å†™æç¤ºè¯
        rewritten = llm.invoke([HumanMessage(content=rewrite_prompt)])
        search_query = rewritten.content.strip()
        print(f"  åŸå§‹æŸ¥è¯¢: {query}")
        print(f"  æ”¹å†™æŸ¥è¯¢: {search_query}")
    else:
        search_query = query
    results = search_tool.invoke(search_query)

    # æ ¼å¼åŒ–ç»“æœ
    if isinstance(results, list):
        formatted = "\n\n".join([
            f"æ¥æº {i + 1}: {r.get('url', 'N/A')}\næœç´¢å†…å®¹ï¼š{r.get('content', '')}"
            for i, r in enumerate(results)
        ])
    else:
        formatted = str(results)

    state["search_results"] = formatted
    return state


def skip_search(state: AgentState) -> AgentState:
    """è·³è¿‡æœç´¢çš„èŠ‚ç‚¹ï¼ˆç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼‰"""
    state["current_step"] = "ğŸ’­ æ— éœ€æœç´¢ï¼Œç›´æ¥å›ç­”..."
    return state


def reflect_on_results(state: AgentState) -> AgentState:
    """
    åæ€èŠ‚ç‚¹ï¼šè¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜

    è¿™æ˜¯ Agentic RAG çš„å…³é”®è¿›é˜¶ç‚¹ï¼š
    - LLM è¯„ä¼°æ£€ç´¢åˆ°çš„ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿã€æ˜¯å¦ç›¸å…³
    - å¦‚æœä¸è¶³ï¼Œç”Ÿæˆæ”¹è¿›çš„æŸ¥è¯¢å¹¶è§¦å‘é‡æ–°æœç´¢
    - æœ€å¤šå¾ªç¯ max_loops æ¬¡ï¼Œé˜²æ­¢æ— é™å¾ªç¯
    """
    state["current_step"] = "ğŸ¤” æ­£åœ¨è¯„ä¼°æ£€ç´¢ç»“æœ..."

    query = state["current_query"]
    loop_count = state.get("loop_count", 0)
    max_loops = state.get("max_loops", 3)

    # æ”¶é›†æ‰€æœ‰æ£€ç´¢ç»“æœ
    context_parts = []
    if state.get("local_contexts"):
        context_parts.append(f"æœ¬åœ°çŸ¥è¯†åº“ç»“æœ:\n{state['local_contexts']}")
    if state.get("search_results"):
        context_parts.append(f"ç½‘ç»œæœç´¢ç»“æœ:\n{state['search_results']}")

    all_contexts = "\n\n".join(context_parts) if context_parts else "æ— æ£€ç´¢ç»“æœ"

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœï¼Œç›´æ¥æ ‡è®°ä¸ºä¸è¶³
    if not context_parts:
        state["reflection_result"] = "insufficient"
        state["reflection_reason"] = "æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•ç»“æœ"
        state["loop_count"] = loop_count + 1
        return state

    # è®© LLM è¯„ä¼°ç»“æœè´¨é‡
    reflect_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æ£€ç´¢ç»“æœæ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

## ç”¨æˆ·é—®é¢˜
{query}

## æ£€ç´¢ç»“æœ
{all_contexts[:3000]}  # é™åˆ¶é•¿åº¦é¿å… token è¿‡å¤š

## è¯„ä¼°æ ‡å‡†
1. SUFFICIENTï¼ˆå……åˆ†ï¼‰ï¼šæ£€ç´¢ç»“æœç›´æ¥å›ç­”äº†é—®é¢˜ï¼Œä¿¡æ¯å®Œæ•´ã€ç›¸å…³
2. INSUFFICIENTï¼ˆä¸è¶³ï¼‰ï¼šæ£€ç´¢ç»“æœç›¸å…³ä½†ä¸å®Œæ•´ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯
3. IRRELEVANTï¼ˆä¸ç›¸å…³ï¼‰ï¼šæ£€ç´¢ç»“æœä¸é—®é¢˜æ— å…³

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼‰
RESULT: [SUFFICIENT/INSUFFICIENT/IRRELEVANT]
REASON: [ä¸€å¥è¯è¯´æ˜åŸå› ]
REFINED_QUERY: [å¦‚æœæ˜¯ INSUFFICIENTå’ŒIRRELEVANTï¼Œç»™å‡ºæ”¹è¿›çš„æœç´¢æŸ¥è¯¢ï¼›å¦åˆ™ç•™ç©º]

è¯·è¯„ä¼°ï¼š"""

    response = llm.invoke([HumanMessage(content=reflect_prompt)])
    result_text = response.content.strip()

    # è§£æ LLM è¾“å‡º
    reflection_result = "sufficient"  # é»˜è®¤å……åˆ†
    reflection_reason = ""
    refined_query = ""

    for line in result_text.split("\n"):
        line = line.strip()
        if line.startswith("RESULT:"):
            result_value = line.replace("RESULT:", "").strip().upper()
            if result_value in ["SUFFICIENT", "INSUFFICIENT", "IRRELEVANT"]:
                reflection_result = result_value.lower()
        elif line.startswith("REASON:"):
            reflection_reason = line.replace("REASON:", "").strip()
        elif line.startswith("REFINED_QUERY:"):
            refined_query = line.replace("REFINED_QUERY:", "").strip()

    # æ›´æ–°çŠ¶æ€
    state["reflection_result"] = reflection_result
    state["reflection_reason"] = reflection_reason
    state["refined_query"] = refined_query if refined_query else query
    state["loop_count"] = loop_count + 1

    # æ‰“å°åæ€ç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"  ğŸ” åæ€ç»“æœ: {reflection_result}")
    print(f"  ğŸ“ åŸå› : {reflection_reason}")
    if reflection_result == "insufficient" and refined_query:
        print(f"  ğŸ”„ æ”¹è¿›æŸ¥è¯¢: {refined_query}")
    print(f"  ğŸ“Š å½“å‰å¾ªç¯: {state['loop_count']}/{max_loops}")

    return state


def refine_search(state: AgentState) -> AgentState:
    """
    æ”¹è¿›æœç´¢èŠ‚ç‚¹ï¼šä½¿ç”¨æ”¹è¿›åçš„æŸ¥è¯¢é‡æ–°æœç´¢

    å½“ Reflector åˆ¤æ–­ç»“æœä¸è¶³æ—¶ï¼Œç”¨æ”¹è¿›çš„æŸ¥è¯¢é‡æ–°æ£€ç´¢
    """
    state["current_step"] = "ğŸ”„ æ­£åœ¨ä½¿ç”¨æ”¹è¿›çš„æŸ¥è¯¢é‡æ–°æœç´¢..."

    refined_query = state.get("refined_query", state["current_query"])
    search_type = state.get("search_type", "web")

    print(f"  ğŸ”„ æ”¹è¿›æœç´¢: {refined_query}")

    # æ ¹æ®æœç´¢ç±»å‹æ‰§è¡Œæœç´¢
    if search_type == "local":
        result = get_rag_manager().query(refined_query, top_n=5)
        # è¿½åŠ åˆ°ç°æœ‰ç»“æœ
        existing = state.get("local_contexts", "")
        state["local_contexts"] = existing + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + result["formatted"]
        # è¿½åŠ æ¥æº
        new_sources = [
            {"type": "local", "source": ctx.get("metadata", {}).get("source", ""), "score": float(ctx.get("score", 0))}
            for ctx in result["contexts"]
        ]
        state["sources"] = state.get("sources", []) + new_sources

    elif search_type == "web":
        results = search_tool.invoke(refined_query)
        if isinstance(results, list):
            formatted = "\n\n".join([
                f"æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹ï¼š{r.get('content', '')}"
                for r in results
            ])
        else:
            formatted = str(results)
        existing = state.get("search_results", "")
        state["search_results"] = existing + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + formatted

    elif search_type == "hybrid":
        # æ··åˆæœç´¢
        local_result = get_rag_manager().query(refined_query, top_n=3)
        web_results = search_tool.invoke(refined_query)

        existing_local = state.get("local_contexts", "")
        state["local_contexts"] = existing_local + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + local_result["formatted"]

        if isinstance(web_results, list):
            formatted_web = "\n\n".join([
                f"æ¥æº: {r.get('url', 'N/A')}\nå†…å®¹: {r.get('content', '')}"
                for r in web_results
            ])
        else:
            formatted_web = str(web_results)
        existing_web = state.get("search_results", "")
        state["search_results"] = existing_web + "\n\n--- æ”¹è¿›æœç´¢ç»“æœ ---\n" + formatted_web

    return state