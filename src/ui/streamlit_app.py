"""
Streamlit Web UI

å¯åŠ¨æ–¹å¼ï¼š
    cd smart-search-assistant
    streamlit run src/ui/streamlit_app.py

åŠŸèƒ½ï¼š
    - å¯¹è¯å¼é—®ç­”ç•Œé¢
    - æ–‡æ¡£ä¸Šä¼ å’Œç®¡ç†
    - å®æ—¶æ˜¾ç¤ºæœç´¢çŠ¶æ€
    - æ¥æºè¿½æº¯å±•ç¤º
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼ˆè§£å†³ src.xxx å¯¼å…¥é—®é¢˜ï¼‰
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

import streamlit as st
import time
from typing import Optional

# è®¾ç½®é¡µé¢é…ç½®ï¼ˆå¿…é¡»åœ¨å…¶ä»– st è°ƒç”¨ä¹‹å‰ï¼‰
st.set_page_config(
    page_title="Smart Search Assistant",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.graph_advanced import graph_advanced, create_initial_state
from src.rag.rag_manager import RAGManager


def init_session_state():
    """åˆå§‹åŒ– session state"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = f"streamlit-{int(time.time())}"
    if "rag_manager" not in st.session_state:
        st.session_state.rag_manager = RAGManager.get_instance()


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    st.sidebar.title("âš™ï¸ è®¾ç½®")

    # åŠŸèƒ½å¼€å…³
    st.sidebar.subheader("åŠŸèƒ½é€‰é¡¹")
    use_multi_query = st.sidebar.checkbox("Multi-Query æ‰©å±•", value=True, help="å°†é—®é¢˜æ‰©å±•ä¸ºå¤šä¸ªæŸ¥è¯¢")
    max_loops = st.sidebar.slider("æœ€å¤§å¾ªç¯æ¬¡æ•°", 1, 5, 3, help="åæ€å¾ªç¯çš„æœ€å¤§æ¬¡æ•°")

    st.sidebar.divider()

    # çŸ¥è¯†åº“ç®¡ç†
    st.sidebar.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")

    # æ–‡æ¡£ä¸Šä¼ 
    uploaded_file = st.sidebar.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£",
        type=["pdf", "txt", "md"],
        help="æ”¯æŒ PDFã€TXTã€Markdown æ ¼å¼"
    )

    if uploaded_file:
        if st.sidebar.button("ğŸ“¥ å¯¼å…¥æ–‡æ¡£"):
            with st.spinner("æ­£åœ¨å¯¼å…¥æ–‡æ¡£..."):
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                import tempfile
                import os
                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name

                try:
                    rag = st.session_state.rag_manager
                    chunks = rag.add_document(tmp_path)
                    st.sidebar.success(f"âœ… å·²å¯¼å…¥ {chunks} ä¸ªæ–‡æ¡£å—")
                except Exception as e:
                    st.sidebar.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
                finally:
                    os.unlink(tmp_path)

    # æ˜¾ç¤ºå·²å¯¼å…¥æ–‡æ¡£
    rag = st.session_state.rag_manager
    doc_count = rag.count()
    documents = rag.list_documents()

    st.sidebar.metric("æ–‡æ¡£å—æ•°é‡", doc_count)

    if documents:
        with st.sidebar.expander(f"ğŸ“„ å·²å¯¼å…¥ {len(documents)} ä¸ªæ–‡æ¡£"):
            for doc in documents:
                st.write(f"â€¢ {doc}")

    # æ¸…ç©ºæŒ‰é’®
    if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“", type="secondary"):
        rag.clear()
        st.sidebar.success("çŸ¥è¯†åº“å·²æ¸…ç©º")
        st.rerun()

    st.sidebar.divider()

    # ä¼šè¯ç®¡ç†
    st.sidebar.subheader("ğŸ’¬ ä¼šè¯ç®¡ç†")
    if st.sidebar.button("ğŸ”„ æ–°å»ºå¯¹è¯"):
        st.session_state.messages = []
        st.session_state.thread_id = f"streamlit-{int(time.time())}"
        st.rerun()

    return use_multi_query, max_loops


def render_chat_history():
    """æ¸²æŸ“èŠå¤©å†å²"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # æ˜¾ç¤ºæ¥æºï¼ˆå¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ï¼‰
            if message["role"] == "assistant" and "sources" in message:
                sources = message["sources"]
                if sources:
                    with st.expander(f"ğŸ“š æ¥æº ({len(sources)} æ¡)"):
                        for i, src in enumerate(sources, 1):
                            st.write(f"{i}. [{src['type']}] {src['source']}")


def process_query(query: str, use_multi_query: bool, max_loops: int) -> dict:
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    config = {"configurable": {"thread_id": st.session_state.thread_id}}
    state = create_initial_state(
        query=query,
        use_multi_query=use_multi_query,
        max_loops=max_loops
    )

    result = graph_advanced.invoke(state, config)

    return {
        "answer": result.get("final_answer", ""),
        "sources": result.get("sources", []),
        "search_type": result.get("search_type", ""),
        "loop_count": result.get("loop_count", 0),
        "reflection_result": result.get("reflection_result", ""),
        "expanded_queries": result.get("expanded_queries", [])
    }


def main():
    """ä¸»å‡½æ•°"""
    init_session_state()

    # æ ‡é¢˜
    st.title("ğŸ” Smart Search Assistant")
    st.caption("åŸºäº LangGraph çš„æ™ºèƒ½æœç´¢åŠ©æ‰‹ | Multi-Query | Reflector | RAG")

    # ä¾§è¾¹æ 
    use_multi_query, max_loops = render_sidebar()

    # èŠå¤©å†å²
    render_chat_history()

    # è¾“å…¥æ¡†
    if query := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)

        # å¤„ç†æŸ¥è¯¢
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
                status_placeholder = st.empty()

                # æ‰§è¡ŒæŸ¥è¯¢
                result = process_query(query, use_multi_query, max_loops)

                # æ˜¾ç¤ºå…ƒä¿¡æ¯
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æœç´¢ç±»å‹", result["search_type"])
                with col2:
                    st.metric("å¾ªç¯æ¬¡æ•°", result["loop_count"])
                with col3:
                    st.metric("åæ€ç»“æœ", result["reflection_result"])

                # æ˜¾ç¤ºæ‰©å±•æŸ¥è¯¢
                if result["expanded_queries"]:
                    with st.expander("ğŸ”„ æ‰©å±•æŸ¥è¯¢"):
                        for i, q in enumerate(result["expanded_queries"], 1):
                            st.write(f"{i}. {q}")

                # æ˜¾ç¤ºç­”æ¡ˆ
                st.markdown(result["answer"])

                # æ˜¾ç¤ºæ¥æº
                if result["sources"]:
                    with st.expander(f"ğŸ“š ä¿¡æ¯æ¥æº ({len(result['sources'])} æ¡)"):
                        for i, src in enumerate(result["sources"], 1):
                            source_text = src.get("source", "N/A")
                            score = src.get("score", 0)
                            st.write(f"{i}. [{src['type']}] {source_text[:80]}... (ç›¸å…³åº¦: {score:.2f})")

        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({
            "role": "assistant",
            "content": result["answer"],
            "sources": result["sources"]
        })


if __name__ == "__main__":
    main()
